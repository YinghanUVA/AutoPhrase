{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "# hypers\n",
    "dataset_names = ['kp20k', 'inspec', 'krapivin', 'semeval', 'duc', 'nus']\n",
    "root_path = \"/zf18/yw9fm/KPG_Project\"\n",
    "data_path = os.path.join(root_path,\"data\")\n",
    "DEC_MODEL = \"decode_model_500000_1587513120\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28033814570162324"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salient check\n",
    "# how many keywords lie in the title\n",
    "result = []\n",
    "for idx, d in enumerate(data):\n",
    "    title = d['title'].lower()\n",
    "    kw = d['keywords']\n",
    "    tmp = 0\n",
    "    if len(kw)==0:\n",
    "        continue\n",
    "    for keyword in kw:\n",
    "        if keyword.lower() in title:\n",
    "            tmp += 1.0\n",
    "    result.append(tmp/len(kw))\n",
    "sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4952434232199048"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salient check\n",
    "# how many keywords lie in the abstract\n",
    "result = []\n",
    "for idx, d in enumerate(data):\n",
    "    abstract = d['abstract'].lower()\n",
    "    kw = d['keywords']\n",
    "    tmp = 0\n",
    "    if len(kw)==0:\n",
    "        continue\n",
    "    for keyword in kw:\n",
    "        if keyword.lower() in abstract:\n",
    "            tmp += 1.0\n",
    "    result.append(tmp/len(kw))\n",
    "sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45044517558308567"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salient check\n",
    "# how many keywords lie in the neither\n",
    "result = []\n",
    "for idx, d in enumerate(data):\n",
    "    title = d['title'].lower()\n",
    "    kw = d['keywords']\n",
    "    abstract = d['abstract'].lower()\n",
    "    tmp = 0\n",
    "    for keyword in kw:\n",
    "        if keyword.lower() not in title and keyword.lower() not in abstract:\n",
    "            tmp += 1.0\n",
    "    result.append(tmp/len(kw))\n",
    "sum(result)/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many keywords lie in the generated summary\n",
    "result = []\n",
    "dec_dir = '/zf18/yw9fm/KPG_Project/log/kp20k/decode_model_495000_1580986035_his'\n",
    "gen_dir = os.path.join(dec_dir,'rouge_dec_dir')\n",
    "ref_dir = os.path.join(dec_dir,'rouge_ref')\n",
    "gen = os.listdir(gen_dir)\n",
    "ref = os.listdir(ref_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19987\n"
     ]
    }
   ],
   "source": [
    "assert len(os.listdir(gen_dir)) == len(os.listdir(ref_dir))\n",
    "print(len(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000000_reference.txt'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = sorted(gen)\n",
    "ref = sorted(ref)\n",
    "ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp20k_test_path = os.path.join(data_path,'kp20k','kp20k_test.json')\n",
    "test_data = [json.loads(line) for line in open(kp20k_test_path, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'abstract': u'Autoimmune polyendocrinopathy candidiasis ectodermal dystrophy (APECED) is a monogenic autosomal recessive disease caused by mutations in the autoimmune regulator (AIRE) gene and, as a syndrome, is characterized by chronic mucocutaneous candidiasis and the presentation of various autoimmune diseases. During the last decade, research on APECED and AIRE has provided immunologists with several invaluable lessons regarding tolerance and autoimmunity. This review describes the clinical and immunological features of APECED and discusses emerging alternative models to explain the pathogenesis of the disease.',\n",
       " u'keywords': u'apeced;aire;chronic mucocutaneous candidiasis;il-17;il-22',\n",
       " u'title': u'Autoimmune polyendocrinopathy candidiasis ectodermal dystrophy: known and novel aspects of the syndrome'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4470884403471378"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat = []\n",
    "for i in range(len(ref)):\n",
    "    tmp_ref_dir = ref[i]\n",
    "    tmp_gen_dir = gen[i]\n",
    "    with open(os.path.join(gen_dir,tmp_gen_dir)) as f:\n",
    "        tmp_result = f.readlines()\n",
    "    keywords = test_data[i]['keywords'].encode('utf-8').strip().split(';')\n",
    "    tmp_result = [line.rstrip() for line in tmp_result]\n",
    "    result = ' '.join(tmp_result)\n",
    "    abstract = test_data[i]['abstract']\n",
    "    title = test_data[i]['title']\n",
    "    art = ' '.join((title, abstract)).encode('utf-8').strip()\n",
    "#     print(result, keywords)\n",
    "    tmp = 0\n",
    "    for kw in keywords:\n",
    "        if kw in art:\n",
    "            tmp += 1.0\n",
    "    stat.append(tmp/len(keywords))\n",
    "sum(stat)/len(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3117768803918168"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(stat)/len(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in stat:\n",
    "    if i > 0:\n",
    "        cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environment for enhancement of soft shadows\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environments : a case study of soft shadows\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environment : a case study of soft shadows\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environment : a case study for soft shadows\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environments : a case study for soft shadows\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environment for enhancement of soft shadow\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environment : a case study for soft shadow production\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environments : a case study for soft shadow production\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environment : a case study in ar\n",
      "shadow and detail multi - layer shadow and detail algorithm for the generation of soft shadows based on real light sources in ar - based ar - augmented reality environments : a case study in ar\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of voting\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of voting scheme\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of learning\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of voting schemes\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of decision support\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in a more dynamic process\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of decision trees\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in modular neural network systems\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of decision making\n",
      "a new mnn architecture for modular neural network decision fusion in modular neural networks : a case study in the presence of voting scheme and its application to decision fusion in the presence of dynamic process\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical shared path protection in optical networks\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical shared path protection in wdm optical networks\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical shared path protection in wdm networks\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical shared path protection in optical wireless networks\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical regenerators ( oeos ) with optical transmission impairments\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical regenerators ( oeos ) with optical [UNK]\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical regenerators ( [UNK] ) with optical [UNK]\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical regenerators ( oeos ) for optical networks\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical regenerators ( oeos ) with optical transmission\n",
      "shared path protection in optical backbone networks : a generalized sharing concept and 1:n shared path protection for optical - ofdm optical backbone networks and optical - electronic -optical regenerators ( [UNK] ) with optical transmission\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous transportation problems with restricted inflow set flow and inflow systems\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set flow problems\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set flow and inflow systems\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set with inflow systems\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set flow constraints\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set flow models\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set flow conditions\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set with inflow conditions\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set with semi-continuous variables\n",
      "semi-continuous network flow problems with restricted inflow set with variable upper upper bounds and variable upper upper upper upper upper upper upper upper bounds for semi-continuous network flow problems with restricted inflow set with restricted inflow\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion in the probabilistic information retrieval model\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion with context in the okapi system\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion with context in okapi system\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion in the probabilistic information retrieval framework\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion in the probabilistic information retrieval platform\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion with context in the java domain\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion in the probabilistic information retrieval system\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion in the probabilistic information retrieval\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning approaches and query expansion with contextual information retrieval\n",
      "an extensible java - based platform for contextual retrieval in java - based contextual retrieval based on the probabilistic information retrieval model and blind / machine learning and query expansion with context in the contextual information\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on genetic programming and genetic algorithms\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on genetic algorithms and genetic algorithms\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on consumer preference patterns and genetic programming\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on genetic programming and consumer preference patterns\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on consumer preference patterns and genetic relaxations\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on consumer preference patterns and genetic encoding\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on genetic programming and branch and bound\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on genetic algorithms and genetic algorithm\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on genetic programming and genetic algorithm\n",
      "a genetic algorithm for the product line selection and pricing problem based on genetic encoding and genetic algorithms : application to the product line selection and pricing problem based on genetic programming and consumer preference\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a special k-hop - connected set\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : a case study of the distributed greedy algorithm\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a set of ad hoc networks\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a special k-hop connected k-dominating set\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : a case study of the distributed greedy algorithms\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a special k-hop connected set\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a set of network nodes\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a special k-hop - connected node\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a special k-hop - connected\n",
      "distributed greedy algorithms for coordinating the routing of messages through a k- spr set in the presence of k- spr sets in wireless ad hoc networks : the case of a special k-hop - connected greedy\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks and its application to dynamic sleep scheduling of wireless sensor networks\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks and its application to dynamic sleep scheduling in wireless sensor networks\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks and its application to dynamic sleep scheduling of wireless sensors\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensors\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks and its application to dynamic sleep scheduling of sensory data\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of dynamic sleep\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks and its application to dynamic sleep scheduling of mobile robots\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of dynamic optimization\n",
      "a novel action - dependent adaptive critic design for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of wireless sensor networks in wireless sensor networks for dynamic optimization of sleep\n"
     ]
    }
   ],
   "source": [
    "for i in [89,98,120,134,143,154,159,275]:\n",
    "    tmp_gen_dir = gen[i]\n",
    "    result =''\n",
    "    with open(os.path.join(gen_dir,tmp_gen_dir)) as f:\n",
    "        for line in f:\n",
    "            result += line\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'a feedback vertex set of 2-degenerate graphs', u'a feedback vertex set of a graph g is a set s  of its vertices such that the subgraph induced by v(g)?s is a forest. the cardinality of a minimum feedback vertex set of g  is denoted by ?(g). a graph g is 2-degenerate  if each subgraph g? of g has a vertex v  such that dg?(v)?2. in this paper, we prove that ?(g)?2n/5 for any 2-degenerate n-vertex graph g and moreover, we show that this bound is tight. as a consequence, we derive a polynomial time algorithm, which for a given 2-degenerate n-vertex graph returns its feedback vertex set of cardinality at most 2n/5.', [u'feedback vertex set', u'decycling set', u'2-degenerate graphs'])\n",
      "(u'hybrid analytical modeling of pending cache hits, data prefetching, and mshrs', u'this article proposes techniques to predict the performance impact of pending cache hits, hardware prefetching, and miss status holding register resources on superscalar microprocessors using hybrid analytical models. the proposed models focus on timeliness of pending hits and prefetches and account for a limited number of mshrs. they improve modeling accuracy of pending hits by 3.9x and when modeling data prefetching, a limited number of mshrs, or both, these techniques result in average errors of 9.5% to 17.8%. the impact of non-uniform dram memory latency is shown to be approximated well by using a moving average of memory access latency.', [u'performance', u'analytical modeling', u'pending hit', u'data prefetching', u'miss status holding register'])\n",
      "(u'autoimmune polyendocrinopathy candidiasis ectodermal dystrophy: known and novel aspects of the syndrome', u'autoimmune polyendocrinopathy candidiasis ectodermal dystrophy (apeced) is a monogenic autosomal recessive disease caused by mutations in the autoimmune regulator (aire) gene and, as a syndrome, is characterized by chronic mucocutaneous candidiasis and the presentation of various autoimmune diseases. during the last decade, research on apeced and aire has provided immunologists with several invaluable lessons regarding tolerance and autoimmunity. this review describes the clinical and immunological features of apeced and discusses emerging alternative models to explain the pathogenesis of the disease.', [u'apeced', u'aire', u'chronic mucocutaneous candidiasis', u'il-17', u'il-22'])\n",
      "(u'numerical solution of a three-dimensional solidification problem in aluminium casting', u'in this paper, we consider an enthalpy formulation for a two-phase stefan problem arising from the solidification of aluminium during casting process. we solve this free boundary problem in a time varying three-dimensional domain and consider convective heat transfer in the liquid phase. the resulting equations are discretized using a characteristics method in time and a finite element method in space, and we propose a numerical algorithm to solve the obtained nonlinear discretized problem. finally, numerical results are given which are compared with industrial experimental measurements.', [u'casting', u'thermal', u'conduction', u'convection', u'finite element'])\n",
      "(u'definition and recognition of rib features in aircraft structural part', u'in this research, a new type of manufacturing feature that is commonly observed in aircraft structural parts, known as ribs, is defined and implemented using the object-oriented software engineering approach. the rib feature type is defined as a set of constrained and adjacent faces of a part which are associated with a set of specific rib machining operations. computerized numerical control (cnc) operation experience and the machining knowledge are leveraged by analysing typical geometry interactions when generating machining tool paths where such knowledge and experience are abstracted as rules of process planning. then those abstracted machining process rules are implemented in a feature recognition algorithm on top of an existing and holistic attribute adjacency graph solution to extract seed faces, identify individual local rib elements and further cluster these newly identified local rib elements into groups for the ease of machining operations. out of the potentially different combinations of local rib elements, those optimised cluster groups are merged into the top-level rib features. the enhanced recognition algorithm is presented in details. a pilot system has already been developed and applied for machining many advanced aircraft structural parts in a large aircraft manufacturer. observations and conclusions are presented at the end.', [u'feature recognition', u'rib', u'aircraft structural part', u'machining feature'])\n",
      "(u'an algebraic approach to guarantee harmonic balance method using grobner base', u'harmonic balance (hb) method is well known principle for analyzing periodic oscillations on nonlinear networks and systems. because the hb method has a truncation error, approximated solutions have been guaranteed by error bounds. however, its numerical computation is very time-consuming compared with solving the hb equation. this paper proposes an algebraic representation of the error bound using grobner base. the algebraic representation enables to decrease the computational cost of the error bound considerably. moreover, using singular points of the algebraic representation, we can obtain accurate break points of the error bound by collisions.', [u'harmonic balance method', u'error bound', u'grobner base', u'algebraic representation', u'quadratic approximation', u'singular point'])\n",
      "(u'a graph coloring based tdma scheduling algorithm for wireless sensor networks', u'wireless sensor networks should provide with valuable service, which is called service-oriented requirement. to meet this need, a novel distributed graph coloring based time division multiple access scheduling algorithm (gcsa), considering real-time performance for clustering-based sensor network, is proposed in this paper, to determine the smallest length of conflict-free assignment of timeslots for intra-cluster transmissions. gcsa involves two phases. in coloring phase, networks are modeled using graph theory, and a distributed vertex coloring algorithm, which is a distance-2 coloring algorithm and can get colors near to ((updelta +1)), is proposed to assign a color to each node in the network. then, in scheduling phase, each independent set is mapped to a unique timeslot according to the sets priority which is obtained by considering network structure. the experimental results indicate that gcsa can significantly decrease intra-cluster delay and increase intra-cluster throughput, which satisfies real-time performance as well as communication reliability.', [u'tdma', u'distributed', u'graph coloring', u'clustering', u'real-time'])\n",
      "(u'building model as a service to support geosciences', u'model as a service (maas) concept and architecture is introduced to support geoscience modeling. maas enables various geoscience models to be published as services that can be accessed through a simple web interface. maas automates the processes of configuring machines, setting up and running models, and managing model outputs. maas provides new guidance for geoscientists seeking solutions to address the computing demands for geoscience models.', [u'cloud computing', u'web service', u'geospatial data', u'model web', u'earthcube', u'big data'])\n",
      "(u'shot change detection using scene-based constraint', u\"a key step for managing a large video database is to partition the video sequences into shots. past approaches to this problem tend to confuse gradual shot changes with changes caused by smooth camera motions. this is in part due to the fact that camera motion has not been dealt with in a more fundamental way. we propose an approach that is based on a physical constraint used in optical flow analysis, namely, the total brightness of a scene point across two frames should remain constant if the change across two frames is a result of smooth camera motion. since the brightness constraint would be violated across a shot change, the detection can be based on detecting the violation of this constraint. it is robust because it uses only the qualitative aspect of the brightness constraint-detecting a scene change rather than estimating the scene itself. moreover, by tapping on the significant know-how in using this constraint, the algorithm's robustness is further enhanced. experimental results are presented to demonstrate the performance of various algorithms. it was shown that our algorithm is less likely to interpret gradual camera motions as shot changes, resulting in a significantly better precision performance than most other algorithms.\", [u'shot change detection', u'optical flow', u'video segmentation'])\n",
      "(u'tail asymptotics for hol priority queues handling a large number of independent stationary sources', u'in this paper we study the asymptotics of the tail of the buffer occupancy distribution in buffers accessed by a large number of stationary independent sources and which are served according to a strict hol priority rule. as in the case of single buffers, the results are valid for a very general class of sources which include long-range dependent sources with bounded instantaneous rates. we first consider the case of two buffers with one of them having strict priority over the other and we obtain asymptotic upper bound for the buffer tail probability for lower priority buffer. we discuss the conditions to have asymptotic equivalents. the asymptotics are studied in terms of a scaling parameter which reflects the server speed, buffer level and the number of sources in such a way that the ratios remain constant. the results are then generalized to the case of m buffers which leads to the source pooling idea. we conclude with numerical validation of our formulae against simulations which show that the asymptotic bounds are tight. we also show that the commonly suggested reduced service rate approximation can give extremely low estimates.', [u'priority queues', u'bahadur-rao theorem', u'large deviations', u'cell loss', u'stationary processes', u'tail distributions'])\n",
      "(u'a variant of parallel plane sweep algorithm for multicore systems', u'parallel algorithms used in very large scale integration physical design bring significant challenges for their efficient and effective design and implementation. the rectangle intersection problem is a subset of the plane sweep problem, a topic of computational geometry and a component in design rule checking, parasitic resistance-capacitance extraction, and mask processing flows. a variant of a plane sweep algorithm that is embarrassingly parallel and therefore easily scalable on multicore machines and clusters, while exceeding the best-known parallel plane sweep algorithms on real-world tests, is presented in this letter.', [u'computational geometry', u'multicore', u'physical design', u'plane sweep', u'rectangle intersection'])\n",
      "(u'the antecedents and consequents of user perceptions in information technology adoption', u'a common theme underlying various models that explain information technology adoption is the inclusion of perceptions of an innovation as key independent variables. although a fairly significant body of research that empirically tests these models is now in existence, some questions with regard to both the antecedents as well as the consequents of perceptions remain unanswered. this paper reports the results of a field study examining adoption of an information technology innovation represented by an expert systems application. two research objectives that have both theoretical and practical relevance motivated and guided the study. one, the study challenges an assumption which is implicit in technology acceptance models: that of the non-existence of moderating influences on the relationship between perceptions and adoption decisions. specifically, the study examines the effects of an important moderating influence  personal innovativeness  on this relationship. two, the study seeks to shed further light on the determinants of perceptions by examining the relative efficacy of mass media and interpersonal communication channels in facilitating perception development. theoretical and practical implications that follow from the results are discussed.', [u'information technology adoption', u'personal innovativeness', u'communication channels', u'expert system adoption'])\n",
      "(u'improving classification with latent variable models by sequential constraint optimization', u'in this paper we propose a method to use multiple generative models with latent variables for classification tasks. the standard approach to use generative models for classification is to train a separate model for each class. a novel data point is then classified by the model that attributes the highest probability. the algorithm we propose modifies the parameters of the models to improve the classification accuracy. our approach is made computationally tractable by assuming that each of the models is deterministic, by which we mean that a data-point is associated to only a single latent state. the resulting algorithm is a variant of the support vector machine learning algorithm and in a limiting case the method is similar to the standard perceptron learning algorithm. we apply the method to two types of latent variable models. the first has a discrete latent state space and the second, principal component analysis, has a continuous latent state space. we compare the effectiveness of both approaches on a handwritten digit recognition problem and on a satellite image recognition problem.', [u'latent variable models', u'semi-supervised learning', u'support vector machines', u'pca', u'vector quantization', u'image and character recognition'])\n",
      "(u'a framework for a real time intelligent and interactive brain computer interface', u'a framework for a real time implementation of a brain computer interface. implementation & comparison of different feature extraction methods and classifiers. accuracy & processing time comparison for detection of event related potentials-erp. an implementation of a prototype system using the proposed bci framework. real time eeg data collection and classification of erps using hex-o-speller.', [u'electroencephalography ', u'data collection', u'braincomputer interface ', u'event-related potentials ', u'classification'])\n",
      "(u'characterizing output processes of e-m/e-k/1 queues', u'our goal is to study which conditions of the output process of a queue preserve the increasing failure rate (ifr) property in the interdeparture time. we found that the interdeparture time does not always preserve the ifr property, even if the interarrival time and service time are both erlang distributions with ifr. we give a theoretical analysis and present numerical results of e-m/e-k/1 queues. we show, by numerical examples, that the interdeparture time of e-m/e-k/1 retains the ifr property if m >= k.  ', [u'departure process', u'ph/g/1', u'ifr', u'erlang distribution', u'queueing theory'])\n",
      "(u'a low-complexity down-mixing structure on quadraphonic headsets for surround audio', u\"this work presents a four-channel headset achieving a 5.1-channel-like hearing experience using a low-complexity head-related transfer function (hrtf) model and a simplified reverberator. the proposed down-mixing architecture enhances the sound localization capability of a headset using the hrtf and by simulating multiple sound reflections in a room using moorer's reverberator. since the hrtf has large memory and computation requirements, the common-acoustical-pole and zero (capz) model can be used to reshape the lower-order hrtf model. from a power consumption viewpoint, the capz model reduces computation complexity by approximately 40%. the subjective listening tests in this study shows that the proposed four-channel headset performs much better than stereo headphones. on the other hand, the four-channel headset that can be implemented by off-the-shelf components preserves the privacy with low cost.\", [u'surround audio', u'head-related transfer function', u'virtual loudspeaker', u'reverberation'])\n",
      "(u'security personalization for internet and web services', u'the growth of the internet has been accompanied by the growth of internet services (e.g., e-commerce, e-health). this proliferation of services and the increasing attacks on them by malicious individuals have highlighted the need for service security. the security requirements of an internet or pleb service may be specified in a security policy. the provider of the service is then responsible.,for implementing the security measures contained in the policy. however, a service customer or consumer may have security preferences that are not reflected in the provider security policy in order for set-vice providers to attract and retain customers, as well as reach a wider market, a way of personalizing a security policy to a particular customer is needed we derive the content of an internet or web service security policy and propose a flexible security personalization approach that will allow an internet or web service provider and customer to negotiate to an agreed-upon personalized security policy. in addition, we present two application examples of security policy personalization, and overview the design of our security personalization prototype.', [u'internet services', u'negotiation', u'personalization', u'security', u'security policy', u'web services'])\n",
      "(u'two efficient synchronous double left right arrow asynchronous converters well-suited for networks-on-chip in gals architectures', u'this paper presents two high-throughput, low-latency converters that can be used to convert synchronous communication protocol to asynchronous one and vice versa. we have designed these two hardware components to be used in a globally asynchronous locally synchronous clusterized multi-processor system-on-chip communicating by a fully asynchronous network-on-chip. the proposed architecture is rather generic, and allows the system designer to make various trade-offs between latency and robustness, depending on the selected synchronizer. we have physically implemented the two converters with portable alliance cmos standard cell library and evaluated the architectures by spice simulation for a 90 nm cmos fabrication process.  ', [u'globally asynchronous locally synchronous', u'multi-processor systems-on-chip', u'networks-on-chip', u'synchronization', u'asynchronous fifo'])\n",
      "(u'simulation aided design of organizational structures in manufacturing systems using structuring strategies', u'this paper presents a simulation aided approach for designing organizational structures in manufacturing systems. the approach is based on a detailed modeling and characterization of the forecasted order program, especially of elementary processes, activity networks and manufacturing orders. under the use of the organization modeling system form, that has been developed at the ifab-institute of human and industrial engineering of the university of karlsruhe, structuring strategies-e.g., a process-oriented strategy can be applied in order to design organizational structures in manufacturing systems in a flexible and efficient way. following that, a dynamical analysis of the created manufacturing structures can be carried out with the simulation tool femos, that has also been developed at the ifab-institute. the evaluation module of femos enables to measure the designed solutions with the help of logistical-e.g., lead time degree and organizational-e.g., degree of autonomy key data. this evaluation is the basis for the identification of effective manufacturing systems and also of improvement potentialities. finally, a case study is presented in this paper designing and analyzing different organizational structures of a manufacturing system where gear boxes and robot grip arms were manufactured.', [u'modeling and simulation of manufacturing systems', u'strategies for production systems design'])\n",
      "(u'explicit constructions of selectors and related combinatorial structures, with applications', u'in this paper we present explicit constructions of several combinatorial objects: selectors [cgr00] and selective families [cggpr00], pseudo-random generators for proof systems [abrw00] and fixed waking schedules [gpp00]. as a result, we obtain almost optimal deterministic protocols for broadcasting in unknown directed radio networks [cgr00] and wake-up problem [gpp00]. we also show application of selectors (and its variants) to explicit construction of test sets for coin-weighting problems [dh00]. the parameters of our constructions come close to the best known non-constructive bounds. the constructions are achieved using a common technique, which could be of use for other problems.', [u'object', u'direct', u'applications', u'use', u'paper', u'optimality', u'randomization', u'test'])\n",
      "(u'selective finite element refinement in torsional problems based on the membrane analogy', u'this work presents a selective finite element refinement strategy based on the h-refinement type, in the context of a posteriori error estimates considerations (error computed after the application of the proposed refining scheme), based on a graphical procedure to determine progressively better estimates for the maximum shearing stress in prismatic torsional members. it is structured in an integrated fortran code and delphi based environment to refine an initial arbitrary finite element mesh. the proposed procedure is founded on the membrane analogy that exists between membrane deflections and the torsion problem in the sense that the location of the membrane largest gradient drives the refining procedure. it is shown that multiple level application of the proposed method to two members with different cross sectional geometries with known analytic solutions leads to progressively more accurate estimates (< 1.0% error in most cases) for the maximum shearing stresses calculations. finally, the proposed method is applied to the torsional analysis of an l section member, showing that for this practical case the procedure results in a very accurate calculation as well.', [u'selective h-refinement', u'finite elements', u'membrane analogy', u'torsion', u'maximum shearing stress'])\n",
      "(u'rns montgomery multiplication algorithm for duplicate processing of base transformations', u'this paper proposes a new algorithm to achieve about two-times speedup of modular exponentiation which is implemented by montgomery multiplication based on residue number systems (rns). in rns montgomery multiplication, its performance is determined by two base transformations dominantly. for the purpose of realizing parallel processing of these base transformations, i.e. \"duplicate processing,\" we present two procedures of rns montgomery multiplication, in which rns bases a and b are interchanged, and perform them alternately in modular exponentiation iteration. in an investigation of implementation, 1.87-times speedup has been obtained for 1024-bit modular multiplication. the proposed rns montgomery multiplication algorithm has an advantage in achieving the performance corresponding to that the upper limit of the number of parallel processing units is doubled.', [u'rsa cryptography', u'modular exponentiation', u'residue number systems', u'montgomery multiplication', u'base transformation'])\n",
      "(u'from quality in use to value in the world', u'this paper argues that a focus on quality in use limits the potential of hci. it summarizes how novel approaches such as grounded design can let us go beyond usability to reveal the fit between designs and expected contexts of use. this however is still not enough. it cannot resolve dilemmas about what is and is not a usability problem, or when fit is or is not essential. such dilemmas can only be resolved by an understanding of the value that artifacts aim to deliver in the world. hci must move beyond contextual description to prescriptive approaches to value in the world.', [u'value', u'fit', u'quality', u'design'])\n",
      "(u'comparative study of family 2 gpcrs in fugu rubripes', u'abstract: in this study, members of family 2 gpcrs, one of the largest families of receptors in vertebrates, were isolated and characterized in the genome of the japanese pufferfish, fugu rubripes, and compared with the orthologous genes in other vertebrates. phylogenetic analysis carried out with all vertebrate family 2 gpcr members indicated that calr/cgrpr and crf are the most divergent receptor group within this family and that the remaining members appear to originate from a common ancestral gene precursor.', [u'teleost', u'duplicated genes', u'evolution', u'family 2 gpcrs'])\n",
      "(u'blotto game-based low-complexity fair multiuser subcarrier allocation for uplink ofdma networks', u'this article presents a subcarrier allocation scheme based on a blotto game (sabg) for orthogonal frequency-division multiple access (ofdma) networks where correlation between adjacent subcarriers is considered. in the proposed game, users simultaneously compete for subcarriers using a limited budget. in order to win as many good subcarriers as possible in this game, users are required to wisely allocate their budget. efficient power and budget allocation strategies are derived for users for obtaining optimal throughput. by manipulating the total budget available for each user, competitive fairness can be enforced for the sabg. in addition, the conditions to ensure the existence and uniqueness of nash equilibrium (ne) for the sabg are also established. an low-complexity algorithm that ensures convergence to ne is proposed. simulation results show that the proposed low-complexity sabg can allocate resources fairly and efficiently for both uncorrelated and correlated fading channels.', [u'ofdma', u'subcarrier allocation', u'blotto game', u'fairness', u'efficiency', u'complexity', u'correlated fading'])\n",
      "(u'polymerization conditions influence on the thermomechanical and dielectric properties of unsaturated polyesterstyrene-copolymers', u'the influence of different polymerization conditions like curing agent (mekp) amount and styrene content on the glass transition temperature, the relative dielectric constant as well as loss factors of unsaturated polyesterstyrene-polymer systems after solidification was investigated in depth. with respect to a high average molecular mass and vickers hardness a curing agent content of 3wt% is recommendable. increasing mekp-concentrations cause a slight elevation of the polymers relative dielectric constant as well as of the loss factor. regarding an easy film formation using tape casting a.o. higher styrene amounts lower the viscosity of the resin significantly, the relative dielectric constant and the loss factor decrease also. as an average value a relative dielectric constant of 3 under ambient conditions can be obtained.', [u'unsaturated polyester resin', u'dielectric properties', u'embedded capacitors'])\n",
      "(u'an integration of online and pseudo-online information for cursive word recognition', u'in this paper, we present a novel method to extract stroke order independent information from online data. this information, which we term pseudo-online, conveys relevant information on the offline representation of the word. based on this information, a combination of classification decisions from online and pseudo- online cursive word recognizers is performed to improve the recognition of online cursive words. one of the most valuable aspects of this approach with respect to similar methods that combine online and offline classifiers for word recognition is that the pseudo- online representation is similar to the online signal and, hence, word recognition is based on a single engine. results demonstrate that the pseudo- online representation is useful as the combination of classifiers perform better than those based solely on pure online information.', [u'online', u'offline', u'handwriting', u'cursive', u'word recognition', u'classifier combination'])\n",
      "(u'generation of quasi-gaussian pulses based on correlation techniques', u'the gaussian pulses have been mostly used within communications, where some applications can be emphasized: mobile telephony (gsm), where gmsk signals are used, as well as the uwb communications, where short-period pulses based on gaussian waveform are generated. since the gaussian function signifies a theoretical concept, which cannot be accomplished from the physical point of view, this should be expressed by using various functions, able to determine physical implementations. new techniques of generating the gaussian pulse responses of good precision are approached, proposed and researched in this paper. the second and third order derivatives with regard to the gaussian pulse response are accurately generated. the third order derivates is composed of four individual rectangular pulses of fixed amplitudes, being easily to be generated by standard techniques. in order to generate pulses able to satisfy the spectral mask requirements, an adequate filter is necessary to be applied. this paper emphasizes a comparative analysis based on the relative error and the energy spectra of the proposed pulses.', [u'correlation techniques', u'digital signal processing', u'gaussian pulse', u'spectral analysis', u'ultra-wideband'])\n",
      "(u'learning linear pca with convex semi-definite programming', u'the aim of this paper is to learn a linear principal component using the nature of support vector machines (svms). to this end, a complete svm-like framework of linear pca (svpca) for deciding the projection direction is constructed, where new expected risk and margin are introduced. within this framework, a new semi-definite programming problem for maximizing the margin is formulated and a new definition of support vectors is established. as a weighted case of regular pca, our svpca coincides with the regular pca if all the samples play the same part in data compression. theoretical explanation indicates that svpca is based on a margin-based generalization bound and thus good prediction ability is ensured. furthermore, the robust form of svpca with a interpretable parameter is achieved using the soft idea in svms. the great advantage lies in the fact that svpca is a learning algorithm without local minima because of the convexity of the semi-definite optimization problems. to validate the performance of svpca, several experiments are conducted and numerical results have demonstrated that their generalization ability is better than that of regular pca. finally, some existing problems are also discussed.', [u'principal component analysis', u'statistical learning theory', u'support vector machines', u'margin', u'maximal margin algorithm', u'semi-definite programming', u'robustness'])\n",
      "(u'the neighborhood auditing tool: a hybrid interface for auditing the umls', u'the umls\\'s integration of more than 100 source vocabularies, not necessarily consistent with one another, causes some inconsistencies. the purpose of auditing the umls is to detect such inconsistencies and to suggest how to resolve them while observing the requirement of fully representing the content of each source in the umls. a software tool, called the neighborhood auditing tool (nat), that facilitates umls auditing is presented. the nat supports \"neighborhood-based\" auditing, where, at any given time, an auditor concentrates on a single-focus concept and one of a variety of neighborhoods of its closely related concepts. typical diagrammatic displays of concept networks have a number of shortcomings, so the nat utilizes a hybrid diagram/text interface that features stylized neighborhood views which retain some of the best features of both the diagrammatic layouts and text windows while avoiding the shortcomings. the nat allows an auditor to display knowledge from both the metathesaurus (concept) level and the semantic network (semantic type) level. various additional features of the nat that support the auditing process are described. the usefulness of the nat is demonstrated through a group of case studies. its impact is tested with a study involving a select group of auditors.  ', [u'unified medical language system', u'auditing of terminologies', u'auditing of ontologies', u'auditing of the umls', u'software tool', u'auditing tool', u'user interface', u'hybrid diagram/text user interface'])\n",
      "(u'exclusion regions for optimization problems', u'branch and bound methods for finding all solutions of a global optimization problem in a box frequently have the difficulty that subboxes containing no solution cannot be easily eliminated if they are close to the global minimum. this has the effect that near each global minimum, and in the process of solving the problem also near the currently best found local minimum, many small boxes are created by repeated splitting, whose processing often dominates the total work spent on the global search. this paper discusses the reasons for the occurrence of this so-called cluster effect, and how to reduce the cluster effect by defining exclusion regions around each local minimum found, that are guaranteed to contain no other local minimum and hence can safely be discarded. in addition, we will introduce a method for verifying the existence of a feasible point close to an approximate local minimum. these exclusion regions are constructed using uniqueness tests based on the krawczyk operator and make use of first, second and third order information on the objective and constraint functions.', [u'global optimization', u'validated enclosure', u'existence test', u'uniqueness test', u'inclusion region', u'exclusion region', u'branch and bound', u'cluster effect', u'krawczyk operator', u'kantorovich theorem', u'backboxing', u'affine invariant', u'primary '])\n",
      "(u'learning about meetings', u'most people participate in meetings almost every day, multiple times a day. the study of meetings is important, but also challenging, as it requires an understanding of social signals and complex interpersonal dynamics. our aim in this work is to use a data-driven approach to the science of meetings. we provide tentative evidence that: (i) it is possible to automatically detect when during the meeting a key decision is taking place, from analyzing only the local dialogue acts, (ii) there are common patterns in the way social dialogue acts are interspersed throughout a meeting, (iii) at the time key decisions are made, the amount of time left in the meeting can be predicted from the amount of time that has passed, (iv) it is often possible to predict whether a proposal during a meeting will be accepted or rejected based entirely on the language (the set of persuasive words) used by the speaker.', [u'analysis of meetings', u'applications of machine learning', u'persuasive words'])\n",
      "(u'design and implementation of an expert interface system for integration of photogrammetric and geographic information systems for intelligent preparation and structuring of spatial data', u'preparation of spatial data for geographic information system (gis) simultaneously during feature digitizing process from photogrammetric models reduces data editing phases after feature digitizing process. therefore, the problems, caused by separating spatial data production process from preparation of this data, are overcome as far as possible. to achieve this purpose, specialty and expertise required for spatial data structuring and preparation for gis, should be available in an interface system which establishes a direct connection between photogrammetric and gis systems. in this case, when a user digitizes a feature from a photogrammetric model, decision making process about the method of editing, structuring, layering, and storing of the feature in gis database, can be carried out by such an interface system. thus, according to the capabilities of expert systems for modeling the knowledge and deduction methods of experts, generating an expert interface system between photogrammetric and gis systems, offers a suitable solution for this integration. in this paper, the capabilities of expert systems for intelligent spatial data structuring and preparation simultaneously during feature digitizing process from photogrammetric models, have been investigated. also, design, implementation and test of an expert interface system for integration of photogrammetric and gis systems in order to take advantages of capabilities of both systems simultaneously as one integrated system, has been described.', [u'expert system', u'gis', u'integration', u'photogrammetry', u'spatial data'])\n",
      "(u'wevan  a mechanism for evidence creation and verification in vanets', u'there are traffic situations (e.g. incorrect speeding tickets) in which a given vehicles driving behavior at some point in time has to be proved to a third party. vehicle-mounted sensorial devices are not suitable for this matter since they can be maliciously manipulated. however, surrounding vehicles may give their vision on another ones behavior. furthermore, these data may be shared with the affected vehicle through vanets. in this paper, a vanet-enabled data exchange mechanism called wevan is presented. the goal of this mechanism is to build and verify evidences based on surrounding vehicles (called witnesses) testimonies. due to the short-range nature of vanets, the connectivity to witnesses may be reduced with time  the later their testimonies are requested, the lower the amount of witnesses may be. simulation results show that if testimonies are ordered 5s later, an average of 38 testimonies may be collected in highway scenarios. other intervals and road settings are studied as well.', [u'digital evidence', u'driving behavior', u'vehicular ad-hoc networks ', u'witness'])\n",
      "(u'extensional normalisation and type-directed partial evaluation for typed lambda calculus with sums', u'we present a notion of eta-long beta-normal term for the typed lambda calculus with sums and prove, using grothendieck logical relations, that every term is equivalent to one in normal form. based on this development we give the first type-directed partial evaluator that constructs normal forms of terms in this calculus.', [u'typed lambda calculus', u'strong sums', u'grothendieck logical relations', u'normalisation', u'type-directed partial evaluation'])\n",
      "(u'yet another write-optimized dbms layer for flash-based solid state storage', u'flash-based solid state storage (flashsss) has write-oriented problems such as low write throughput, and limited life-time. especially, flashssds have a characteristic vulnerable to random-writes, due to its control logic utilizing parallelism between the flash memory chips. in this paper, we present a write-optimized layer of dbmss to address the write-oriented problems of flashsss in on-line transaction processing environments. the layer consists of a write-optimized buffer, a corresponding log space, and an in-memory mapping table, closely associated with a novel logging scheme called incremental logging (icl). the icl scheme enables dbmss to reduce page-writes at the least expense of additional page-reads, while replacing random-writes into sequential-writes. through experiments, our approach demonstrated up-to an order of magnitude performance enhancement in i/o processing time compared to the original dbms, increasing the longevity of flashsss by approximately a factor of two.', [u'icl', u'ssd', u'incremental logging', u'flash memory', u'write performance', u'database'])\n",
      "(u'wrinkle development analysis in thin sail-like structures using mitc shell finite elements', u'we propose a method of modelling sail type structures which captures the wrinkling behaviour of such structures. the method is validated through experimental and analytical test cases, particularly in terms of wrinkling prediction. an enhanced wrinkling index is proposed as a valuable measure characterizing the global wrinkling development on the deformed structure. the method is based on a pseudo-dynamic finite element procedure involving non-linear mitc shell elements. the major advantage compared to membrane models generally used for this type of analysis is that no ad hoc wrinkling model is required to control the stability of the structure. we demonstrate our approach to analyse the behaviour of various structures with spherical and cylindrical shapes, characteristic of downwind sails over a rather wide range of shape and constitutive parameters. in all cases convergence is reached and the overall flying shape is most adequately represented, which shows that our approach is a most valuable alternative to standard techniques to provide deeper insight into the physical behaviour. limitations appear only in some very special instances in which local wrinkling-related instabilities are extremely high and would require specific additional treatments, out of the scope of the present study.', [u'sail modelling', u'mitc shells', u'wrinkling', u'wrinkling index'])\n",
      "(u'cliques, holes and the vertex coloring polytope', u'certain subgraphs of a given graph g restrict the minimum number chi(g) of colors that can be assigned to the vertices of g such that the endpoints of all edges receive distinct colors. some of such subgraphs are related to the celebrated strong perfect graph theorem. as it implies that every graph g contains a clique of size chi(g), or an odd hole or an odd anti-hole as an induced subgraph. in this paper, we investigate the impact of induced maximal cliques, odd holes and odd anti-holes on the polytope associated with a new 0-1 integer programming formulation of the graph coloring problem. we show that they induce classes of facet defining, inequalities.  ', [u'combinatorial problems', u'facets of polyhedra', u'graph colorings', u'integer programming'])\n",
      "(u'an experimental validation of a novel clustering approach to pwarx identification', u\"in this paper, the problem of clustering based procedure for the identification of piecewise auto-regressive exogenous (pwarx) models is addressed. this problem involves both the estimation of the parameters of the affine sub-models and the hyperplanes defining the partitions of the state-input regression. in fact, we propose the use of the chiu's clustering algorithm in order to overcome the main drawbacks of the existing methods which are the poor initialization and the presence of outliers. in addition, our approach is able to generate automatically the number of sub-models. simulation results are presented to illustrate the performance of the proposed method. an application of the developed approach to an olive oil esterification reactor is also suggested in order to validate simulation results.\", [u'hybrid systems', u'pwarx models', u'clustering', u'identification', u\"chiu's clustering technique\", u'experimental validation'])\n",
      "(u'a primal-dual approximation algorithm for the asymmetric prize-collecting tsp', u'we present a primal-dual ?log(n)?-approximation algorithm for the version of the asymmetric prize collecting traveling salesman problem, where the objective is to find a directed tour that visits a subset of vertices such that the length of the tour plus the sum of penalties associated with vertices not in the tour is as small as possible. the previous algorithm for the problem (v.h. nguyen and t.t nguyen in int. j. math. oper. res. 4(3):294301, 2012) which is not combinatorial, is based on the held-karp relaxation and heuristic methods such as the frieze et al.s heuristic (frieze et al. in networks 12:2339, 1982) or the recent asadpour et al.s heuristic for the atsp (asadpour etal. in 21st acm-siam symposium on discrete algorithms, 2010). depending on which of the two heuristics is used, it gives respectively 1+?log(n)? and (3+ 8frac{log(n)}{log(log(n))}) as an approximation ratio. our algorithm achieves an approximation ratio of ?log(n)? which is weaker than (3+ 8frac{log(n)}{log(log(n))}) but represents the first combinatorial approximation algorithm for the asymmetric prize-collecting tsp.', [u'prize collecting traveling salesman', u'approximation algorithm', u'primal-dual algorithm'])\n",
      "(u'second order ambient intelligence', u'this text attempts to describe an imagined future of ambient intelligence. it assumes that one day most of the current issues within ambient intelligence will be solved and that a second order ambient intelligence will be formulated, one with new research agendas. it describes several topics and ideas that might be part of this agenda and surmises on the prerequisites for this change.', [u'critique of ambient intelligence', u'temporal design', u'adaptive systems', u'long-term behavior', u'animal machine interaction', u'critical futurism', u'second order ambient intelligence'])\n",
      "(u'pdms prism-glass optical coupling for surface plasmon resonance sensors based on mems technology', u'a miniaturized surface plasmon resonance (spr) chip has been developed for biomedical and chemical analysis with low cost and high performance. the techniques of bulk silicon micromachining and polymer replication were used to fabricate the kretschmann spr sensor composed of a polydimethylsiloxane (pdms) prism, a coupling glass and microchannels. the plasmon properties of thin metal films were investigated theoretically based on fresnel analysis, with optical boundary conditions pertaining to the surface plasmon resonance at the gold/water and gold/air interfaces. the theoretical results show that difference in the refractive index (ri) between the pdms prism and the coupling glass layer affect the precision of the spr angle and the spr curve. meanwhile, the period of the interference fringe attaching on the spr curve increases with an increase in wavelength and a decrease in the refractive index of the coupling glass layer. the gold thickness of 50 nm is required while employing a fixed incident wavelength of 650 nm, to achieve optimum spr excitation conditions and the sensor sensitivity. the characteristics of this spr sensor were evaluated in the angular interrogation mode of employing the incident wavelength of 650 nm in air and water media, respectively. the obtained spr angles were approximately consistent with the theoretical ones.', [u'surface plasmon resolance', u'polymer', u'microfluidic', u'pdms'])\n",
      "(u'isogeometric analysis for strain field measurements', u'in this paper, the potential of isogeometric analysis for strain field measurement by digital image correlation is investigated. digital image correlation (dic) is a full field kinematics measurement technique based on gray level conservation principle and the formulation we adopt allows for using arbitrary displacement bases. the high continuity properties of non-uniform rational b-spline (nurbs) functions are exploited herein as an additional regularization of the initial ill-posed problem. k-refinement is analyzed on an artificial test case where the proposed methodology is shown to outperform the usual finite element-based dic. finally a fatigue tensile test on a thin aluminum sheet is analyzed. strain localization occurs after a certain number of cycles and combination of nurbs into a dic algorithm clearly shows a great potential to improve the robustness of non-linear constitutive law identification.', [u'digital image correlation', u'nurbs', u'strain field measurement', u'isogeometric analysis'])\n",
      "(u'stable computation of the functional variation of the dirichletneumann operator', u'this paper presents an accurate and stable numerical scheme for computation of the first variation of the dirichletneumann operator in the context of eulers equations for ideal free-surface fluid flows. the transformed field expansion methodology we use is not only numerically stable, but also employs a spectrally accurate fourier/chebyshev collocation method which delivers high-fidelity solutions. this implementation follows directly from the authors previous theoretical work on analyticity properties of functional variations of dirichletneumann operators. these variations can be computed in a number of ways, but we establish, via a variety of computational experiments, the superior effectiveness of our new approach as compared with another popular boundary perturbation algorithm (the method of operator expansions).', [u'dirichletneumann operators', u'functional variations', u'boundary perturbation methods', u'high-order/spectral methods', u'water waves'])\n",
      "(u'optimal tool selection for 2.5d milling, part 1: a solid-modeling approach for construction of the voronoi mountain', u'cutter selection is a critical subtask of machining process planning. in this two-part series, we develop a robust approach for the selection of an optimal set of milling cutters for a 2.5d generalized pocket. in the first article ( part 1), we present a solid modeling approach for the construction of the voronoi mountain for the pocket geometry, which is a 3d extension of the voronoi diagram. the major contributions of this work include: ( 1) the development of a robust and systematic procedure for construction of the voronoi mountain for a multiply-connected curvilinear polygon; and ( b) an extension of the voronoi mountain concept to handle open edges.', [u'voronoi mountain ', u'cutter  selection', u'2.5d milling', u'solid modelling', u'open edges'])\n",
      "(u'evaluating the novelty of text-mined rules using lexical knowledge', u'in this paper, we present a new method of estimating the novelty of rules discovered by data-mining methods using wordnet, a lexical knowledge-base of english words. we assess the novelty of a rule by the average semantic distance in a knowledge hierarchy between the words in the antecedent and the consequent of the rule - the more the average distance, more is the novelty of the rule. the novelty of rules extracted by the discotex text-mining system on amazon.com book descriptions were evaluated by both human subjects and by our algorithm. by computing correlation coefficients between pairs of human ratings and between human and automatic ratings, we found that the automatic scoring of rules based on our novelty measure correlates with human judgments about as well as human judgments correlate with one another. @text mining', [u'interesting rules', u'novelty', u'semantic distance', u'knowledge hierarchy', u'wordnet'])\n",
      "(u'visor: vast independence system optimization routine', u'an algorithm is sketched that generates all k maximal independent sets and all m minimal dependent sets of an arbitrary independence system, based on a set of cardinality n having at most 2(n) subsets. with access to an oracle that decides if a set is independent or not. because the algorithm generates all those sets, it solves the problems of finding all maximum independent and minimum dependent sets. those problems are known to be impossible to solve in general in time polynomial in n, k, and m, and they are np hard. the algorithm proposed and used is efficient in the sense that it requires only o(nk + m) or o(k + nm) visits to the oracle, the nonpolynomial part is only related to bitstring comparisons and the like, which can be performed rather quickly and, to some degree, in parallel on a sequential machine. this complexity compares favorably with another algorithm that is o(n(2)k(2)). the design of a computer routine that implements the algorithm in a highly optimized way is discussed. the routine behaves as expected, as is shown by numerical experiments on a range of randomly generated independence systems with n up to n = 34. application on an engineering design problem with n = 28 shows the routine requires almost 10(6) times less visits to the oracle than an exhaustive search, while the time spent in visiting the oracle is still significantly larger than that spent for all other computations together.', [u'combinatorial optimization', u'independence system', u'maximal independent set', u'input/output selection'])\n",
      "(u'superconvergence in high-order galerkin finite element methods', u'in this paper, we shall use local estimates to give the superconvergence of high-order galerkin finite element method for the elliptic equation of second order with constant coefficients by using the symmetric technique and integral identity. we get improved superconvergence on the inner locally symmetric mesh with respect to a point x0 for rectangular and triangular meshes.', [u'superconvergence', u'integral identities', u'locally symmetric meshes', u'elliptic equations of second order'])\n",
      "(u'a review of design pattern mining techniques', u'the quality of a software system highly depends on its architectural design. high quality software systems typically apply expert design experience which has been captured as design patterns. as demonstrated solutions to recurring problems, design patterns help to reuse expert experience in software system design. they have been extensively applied in the industry. mining the instances of design patterns from the source code of software systems can assist in the understanding of the systems and the process of re-engineering them. more importantly, it also helps to trace back to the original design decisions, which are typically missing in legacy systems. this paper presents a review on current techniques and tools for mining design patterns from source code or design of software systems. we classify different approaches and analyze their results in a comparative study. we also examine the disparity of the discovery results of different approaches and analyze possible reasons with some insight.', [u'design pattern', u'reverse engineering', u'discovery'])\n",
      "(u'stabilization of second-order nonholonomic systems in canonical chained form', u'stabilization of a class of second-order nonholonomic systems in canonical chained form is investigated in this paper. first, the models of two typical second-order nonholonomic systems, namely, a three-link planar manipulator with the third joint unactuated, and a kinematic redundant manipulator with all joints free and driven by forces/torques imposing on the end-effector, are presented and converted to second-order chained form by transformations of coordinate and input. a discontinuous control law is then proposed to stabilize all states of the system to the desired equilibrium point exponentially. computer simulation is given to show the effectiveness of the proposed controller.', [u'second-order nonholonomic systems', u'canonical second-order chained form', u'underactuated manipulator', u'discontinuous coordinate transformation', u'discontinuous stabilization'])\n",
      "(u'truthful mechanisms for two-range-values variant of unrelated scheduling', u\"in this paper, we consider a restricted variant of the scheduling problem, where the machines are the strategic players. for this multi-parameter mechanism design problem, the only known truthful mechanisms use task independent allocation algorithms and only have approximation ratio o(m). lavi and swamy first use the cycle monotone condition and design a 3-approximation truthful mechanism for a two value variant in lavi, where the processing time of task j on machine i, say t(ij), can only be either a lower value l(j) or a higher value h(j). we consider a generalized variant. where t(ij) lies in [l(j), l(j)(1+epsilon)] boolean or [h(j), h(j)(1+epsilon)] and epsilon is a parameter satisfying some condition. we consider two special cases, case a when h(j)/l(j) > 2,for all(j) and case b when h(j)/l(j) <= 2, for all j, and give randomized truthful mechanisms with approximation ratio 4(1+epsilon) for both cases. based on these two cases' results, we are also able to deal with the general case of our two-range-values scheduling problem. we use a combination of two mechanisms, which is also a novel method in mechanism design for scheduling problems, and finally we give a randomized truthful mechanism with approximation ratio 7(1+epsilon). although the generalization seems a little incremental, we actually use a very novel technique in the key step of proving truthfulness for case a, as well as a new mechanism scheme for case b. besides, the results in this paper are the first truthful mechanisms with constant approximation ratios when a machine (player) can report infinitely possible values, which is quite different from the two value variant, in which only finite values are available. furthermore, together with lavi and swamy's work, our results suggest that such a task-dependent approach can really do much better for the scheduling unrelated machines problem.  \", [u'truthful mechanism', u'approximation algorithm', u'scheduling'])\n",
      "(u'a note on the relationships among certified discrete log cryptosystems', u'the certified discrete logarithm problem modulo p prime is a discrete logarithm problem under the conditions that the complete factorization of p - 1 is given and by which the base g is certified to be a primitive root mod p. for the cryptosystems based on the intractability of certified discrete logarithm problem, sakurai-shizuya showed that breaking the diffie-hellman key exchange scheme reduces to breaking the shamir 3-pass key transmission scheme with respect to the expected polynomial-time turing reducibility. in this paper, we show that we can remove randomness from the reduction above, and replace the reducibility with the polynomial-time many-one. since the converse reduction is known to hold with respect to the polynomial-time many-one reducibility, our result gives a stronger evidence for that the two schemes are completely equivalent as certified discrete log cryptosystems.', [u'certified discrete logarithm problem', u'order', u'primitive root', u'probabilistic reducibility', u'deterministic reducibility'])\n",
      "(u'hydraulic performance of a large slanted axial-flow pump', u'purpose - the pump of the taipuhe pump station, larger flow discharge, lower head, is one of the largest 150 slanted axial-flow pumps in the world. however, few studies have been done for the larger slanted axial-flow pump on safe operation. the purpose of this paper is to analyze the impeller elevation, unsteady flow, hydraulic thrust and the zero-head flow characteristics of the pump. design/methodology/approach - the flow field in and through the pump was analyzed numerically during the initial stages of the pump design process, then the entire flow passage through the pump was analyzed to calculate the hydraulic thrust to prevent damage to the bearings and improve the operating stability the zero-head pump flow characteristics were analyzed to ensure that the pump will work reliably at much lower heads. findings - the calculated results are in good agreement with experimental data for the pump elevation effects, the performance curve, pressure oscillations, hydraulic thrust and zero-head performance. research limitations/implications - since it is assumed that there is no gap between blades and shroud, gap cavitations are beyond the scope of the paper. originality/value - the paper indicates the slanted axial-flow pump characteristics including the characteristic curves, pressure fluctuations, hydraulic thrust and radial force for normal operating conditions and zero-head conditions. it shows how to guarantee the pump safety operating by computational fluid dynamics.', [u'pumps', u'fluid dynamics', u'force measurement', u'water supply engineering', u'china'])\n",
      "(u'high-radix montgomery modular exponentiation on reconfigurable hardware', u'it is widely recognized that security issues will play a crucial role in the majority of future computer and communication systems. central tools for achieving system security are cryptographic algorithms. this contribution proposes arithmetic architectures which are optimized for modern field programmable gate arrays (fpgas). the proposed architectures perform modular exponentiation with very long integers. this operation is at the heart of many practical public-key algorithms such as rsa and discrete logarithm schemes. we combine a high-radix montgomery modular multiplication algorithm with a new systolic array design. the designs are flexible, allowing any choice of operand and modulus. the new architecture also allows the use of high radices. unlike previous approaches, we systematically implement and compare several variants of our new architecture for different bit lengths. we provide absolute area and timing measures for each architecture. the results allow conclusions about the feasibility and time-space trade-offs of our architecture for implementation on commercially available fpgas. we found that 1,024-bit rsa decryption can be done in 3.1 ms with our fastest architecture.', [u'montgomery', u'modular arithmetic', u'fpga', u'exponentiation', u'rsa', u'systolic array'])\n",
      "(u'combined use of supervised and unsupervised learning for power system dynamic security mapping', u'this paper proposes a new methodology which combines supervised and unsupervised learning for evaluating power system dynamic security. based on the concept of stability margin, pre-fault power system conditions are assigned to the output neurons on the two-dimensional grid with the growing hierarchical self-organizing map technique (ghsom) via supervised artificial neural networks (anns) which perform an estimation of post-fault power system state. the technique estimates the dynamic stability index that corresponds to the most critical value of synchronizing and damping torques of multimachine power systems. ann-based pattern recognition is carried out with the growing hierarchical self-organizing feature mapping in order to provide adaptive neural network architecture during its unsupervised training process. numerical tests, carried out on a ieee 9 bus power system are presented and discussed. the analysis using such method provides accurate results and improves the effectiveness of system security evaluation.', [u'dynamic security assessment', u'synchronizing and damping torques', u'growing hierarchical self-organizing feature map', u'supervised and unsupervised learning', u'stability criteria'])\n",
      "(u'0.35 mu m cmos t/r switch for 2.4 ghz short range wireless applications', u'this paper describes the design and implementation of a transmit/receive switch for 2.4 ghz ism band applications. the t/r switch is implemented in a 0.35 mum bulk cmos process and it occupies 150 mum . 170 mum of die area. a parasitic mosfet model including bulk resistance is used to optimize the physical dimensions of the transistors with regard to insertion loss and isolation. the measured insertion loss is 1.3 db without port matching. simulations using measured s-parameters indicate that an insertion loss of 0.8 db can be obtained with a conjugate match. the measured isolation is 42 db and the maximum transmit power is 16 dbm.', [u't/r switch', u'mosfet switch', u'rf cmos', u'spdt switch'])\n",
      "(u'probabilistic equivalence checking of multiple-valued functions', u'this paper describes a probabilistic method for verifying the equivalence of two multiple-valued functions. each function is hashed to an integer code by transforming it to a integer-valued polynomial and evaluating it for values of variables taken independently and uniformly at random from a finite field. since the polynomial is unique for a given function, if two hash codes are different, then the functions are not equivalent. however, if two hash codes are the same, the functions may or may not be equivalent, because different polynomials may happen to hash to the same code. thus, the method presented in this paper determines the equivalence of two functions with a known (small) probability of error, arising from collisions between inequivalent functions. such a method seems to be an attractive alternative for verifying functions that are too large to be handled by deterministic equivalence checking methods.', [u'multiple-valued function', u'equivalence checking', u'probabilistic verification'])\n",
      "(u'a model and environment for improving multimedia scholarly reading practices', u'the evolution of multimedia document production and diffusion technologies has lead to a significant spread of knowledge in form of pictures and recordings. however, scholarly reading tasks are still principally performed on textual contents. we argue that this is due to a lack of critical and structured tools: (1) to handle the wide spectrum of interpretive operations involved by the polymorphous scholarly reading process; (2) to perform these operations on a heterogeneous multimedia corpus. this firstly calls for identifying fundamental document requirements for such reading practices. then, we present a flexible model and a software environment which enable the reader to structure, annotate, link, fragment, compare, freely organise and spatially lay out documents, and to prepare the writing of their critical comment. we eventually discuss experiments with humanities scholars, and explore new academic reading practices which take advantage of document engineering principles such as multimedia document structuring, publication or sharing.', [u'multimedia scholarly reading', u'multimedia corpus modelling', u'document annotation and structuring', u'spatial hypertexts', u'graphical user interfaces for critical reading'])\n",
      "(u'sensor selection for energy-efficient ambulatory medical monitoring', u'epilepsy affects over three million americans of all ages. despite recent advances, more than 20% of individuals with epilepsy never achieve adequate control of their seizures. the use of a small, portable, non-invasive seizure monitor could benefit these individuals tremendously. however, in order for such a device to be suitable for long-term wear, it must be both comfortable and lightweight. typical state-of-the-art non-invasive seizure onset detection algorithms require 21 scalp electrodes to be placed on the head. these electrodes are used to generate 18 data streams, called channels. the large number of electrodes is inconvenient for the patient and processing 18 channels can consume a considerable amount of energy, a problem for a battery-powered device. in this paper, we describe an automated way to construct detectors that use fewer channels, and thus fewer electrodes. starting from an existing technique for constructing 18 channel patient-specific detectors, we use machine learning to automatically construct reduced channel detectors. we evaluate our algorithm on data from 16 patients used in an earlier study. on average, our algorithm reduced the number of channels from 18 to 4.6 while decreasing the mean fraction of seizure onsets detected from 99% to 97%. for 12 out of the 16 patients, there was no degradation in the detection rate. while the average detection latency increased from 7.8 s to 11.2 s, the average rate of false alarms per hour decreased from 0.35 to 0.19. we also describe a prototype implementation of a single channel eeg monitoring device built using off-the-shelf components, and use this implementation to derive an energy consumption model. using fewer channels reduced the average energy consumption by 69%, which amounts to a 3.3x increase in battery lifetime. finally, we show how additional energy savings can be realized by using a low-power screening detector to rule out segments of data that are obviously not seizures. though this technique does not reduce the number of electrodes needed, it does reduce the energy consumption by an additional 16%.', [u'epilepsy', u'reducing energy consumption', u'channel selection', u'electroencephalography ', u'ambulatory medical monitoring'])\n",
      "(u'process synchronization without long-term interlock', u'a technique is presented for replacing long-term interlocking of shared data by the possible repetition of unprivileged code in case a version number (associated with the shared data) has been changed by another process. four principles of operating system architecture (which have desirable effects on the intrinsic reliability of a system) are presented; implementation of a system adhering to these principles requires that long-term lockout be avoided.', [u'sharing', u'systems', u'synchronization', u'association', u'reliability', u'code', u'architecture', u'operating system', u'implementation', u'process', u'data', u'case', u'version', u'effect'])\n",
      "(u'application of an artificial immune system-based fuzzy neural network to a rfid-based positioning system', u\"due to the rapid development of globalization, which makes supply chain management more complicated, more companies are applying radio frequency identification (rfid), in warehouse management. the obvious advantages of rfid are its ability to scan at high-speed, its penetration and memory. in addition to recycling, use of a rfid system can also reduce business costs, by indentifying the position of goods and picking carts. this study proposes an artificial immune system (ais)-based fuzzy neural network (fnn), to learn the relationship between the rfid signals and the picking cart's position. since the proposed network has the merits of both ais and fnn. it is able to avoid falling into the local optimum and possesses a learning capability. the results of the evaluation of the model show that the proposed ais-based fnn really can predict the picking cart position more precisely than conventional fnn and, unlike an artificial neural network, it is much easier to interpret the training results, since they are in the form of fuzzy if-then rules.  \", [u'radio frequency identification ', u'artificial immune system ', u'genetic algorithms ', u'fuzzy neural network '])\n",
      "(u'single-dimension multidimensional software pipelining for loops', u'traditionally, software pipelining is applied either to the innermost loop of a given loop nest or from the innermost loop to outer loops. this paper proposes a three-step approach, called single-dimension software pipelining (ssp), to software pipeline a loop nest at an arbitrary loop level that has a rectangular iteration space and contains no sibling inner loops in it. the first step identifies the most profitable loop level for software pipelining in terms of initiation rate, data reuse potential, or any other optimization criteria. the second step simplifies the multidimensional data-dependence graph (ddg) of the selected loop level into a one-dimensional ddg and constructs a one-dimensional (1d) schedule. based on the one-dimensional schedule, the third step derives a simple mapping function that specifies the schedule time for the operation instances in the multidimensional loop. the classical modulo scheduling is subsumed by ssp as a special case. ssp is also closely related to hyperplane scheduling, and, in fact, extends it to be resource constrained. we prove that ssp schedules are correct and at least as efficient as those schedules generated by traditional modulo scheduling methods. we extend ssp to schedule imperfect loop nests, which are most common at the instruction level. multiple initiation intervals are naturally allowed to improve execution efficiency. feasibility and correctness of our approach are verified by a prototype implementation in the orc compiler for the ia-64 architecture, tested with loop nests from livermore and spec2000 floating-point benchmarks. preliminary experimental results reveal that, compared to modulo scheduling, software pipelining at an appropriate loop level results in significant performance improvement. software pipelining is beneficial even with prior loop transformations.', [u'algorithms', u'languages', u'software pipelining', u'modulo scheduling', u'loop transformation'])\n",
      "(u'a geometric-based method for recognizing overlapping polygonal-shaped and semi-transparent particles in gray tone images', u'a geometric-based method is proposed to recognize the overlapping particles of different polygonal shapes such as rectangular, regular and/or irregular prismatic particles in a gray tone image. the first step consists in extracting the salient corners, identified by their locations and orientations, of the overlapping particles. although there are certain difficulties like the perspective geometric projection, out of focus, transparency and superposition of the studied particles. then, a new clustering technique is applied to detect the shape by grouping its correspondent salient corners according to the geometric properties of each shape. a simulation process is carried out for evaluating the performance of the proposed method. then, it is particularly applied on a real application of batch cooling crystallization of the ammonium oxalate in pure water. the experimental results show that the method is efficient to recognize the overlapping particles of different shapes and sizes.', [u'salient corner detection', u'contour detection', u'clustering method', u'overlapping particles recognition'])\n",
      "(u'explicit dimension reduction and its applications', u'we construct a small set of explicit linear transformations mapping r-n to r-t, where t = o(log(gamma(-1))epsilon(-2)), such that the l-2 norm of any vector in r-n is distorted by at most 1 +/- epsilon in at least a fraction of 1 - gamma of the transformations in the set. albeit the tradeoff between the size of the set and the success probability is suboptimal compared with probabilistic arguments, we nevertheless are able to apply our construction to a number of problems. in particular, we use it to construct an epsilon-sample (or pseudorandom generator) for linear threshold functions on sn-1 for epsilon = o(1). we also use it to construct an epsilon-sample for spherical digons in sn-1 for epsilon = o(1). this construction leads to an efficient oblivious derandomization of the goemans-williamson max-cut algorithm and similar approximation algorithms (i.e., we construct a small set of hyperplanes such that for any instance we can choose one of them to generate a good solution). our technique for constructing an epsilon-sample for linear threshold functions on the sphere is considerably different than previous techniques that rely on k-wise independent sample spaces.', [u'dimension reduction', u'pseudorandom generator', u'linear threshold functions', u'max-cut', u'johnson lindenstrauss', u'digons'])\n",
      "(u'capital one financial and a decade of experience with newly vulnerable markets: some propositions concerning the competitive advantage of new entrants', u'market share and brand recognition have historically provided advantage to established players in mature industries. the success of capital one, an attacker in the mature credit card industry is therefore interesting, both to researchers and to executives developing strategies. a partial explanation is offered by the theory of newly vulnerable markets. the success of capital one can be partially attributed to its application of information-based strategies to several newly vulnerable markets, allowing it to target and retain the most profitable customers. these strategies sustained double-digit return on equity and double-digit increase in sales volume and profits every year of our study.', [u'newly vulnerable markets', u'information-based strategy', u'market entry', u'differential pricing', u'customer profitability gradient', u'capital one financial', u'information economics'])\n",
      "(u'scene analysis and geometric homology', u\"during the last 10-12 years there has been a dramatic revival of interest in applied geometric problems. geometers have reconsidered a number of questions in infinitesimal mechanics, questions treated by j.c. maxwell and l. cremona  in 1864-70, further developed under the banner of graphical statics , but left largely untouched since the end of the nineteenth century. at the same time, computer scientists have come to recognize that the tools of graphical statics and of applied projective geometry are fundamental to research in scene analysis. a good deal of the recent revival of interest is due to the efforts of the structural topology research group at the university of montreal. the work of this group, reported in the pages of the journal structural topology  (and elsewhere), was a biproduct of research on infinitesimal mechanics, using methods derived from graphical statics, as well as from exterior algebra and its modern offspring, the doubilet-rota-stein double algebra . independently, huffman , duda and hart , and others recognized that maxwell's reciprocal figures could help in deciding whether a given plane image is the projection of a 3d polyhedral scene. more recently, sugihara  and his colleagues in nagoya created what may be considered a pilot project for automated descriptive geometry. they wrote a software package capable of modifying a rough plane sketch, so as to make it a true projection of a 3d scene. the starting point of the during the last 10-12 years there has been a dramatic revival of interest in applied geometric problems. geometers have reconsidered a number of questions in infinitesimal mechanics, questions treated by j.c. maxwell and l. cremona  in 1864-70, further developed under the banner of graphical statics , but left largely untouched since the end of the nineteenth century. at the same time, computer scientists have come to recognize that the tools of graphical statics and of applied projective geometry are fundamental to research in scene analysis. a good deal of the recent revival of interest is due to the efforts of the structural topology research group at the university of montreal. the work of this group, reported in the pages of the journal structural topology  (and elsewhere), was a biproduct of research on infinitesimal mechanics, using methods derived from graphical statics, as well as from exterior a. independently, huffman , duda and hart , and others recognized that maxwell's reciprocal figures could help in deciding whether a given plane image is the projection of a 3d polyhedral scene. more recently, sugihara  and his colleagues in nagoya created what may be considered a pilot project for automated descriptive geometry. they wrote a software package capable of modifying a rough plane sketch, so as to make it a true projection of a 3d scene. the starting point of the projective geometric analysis of scenes is the observation that the set of all three-dimensional realizations ( scenes ) having a given two-dimensional projection (a drawing, or image ) form a linear space. much information about an image, and about its possible spatial interpretations, can be obtained simply by calculating (either locally or globally) the linear dimension (or rank ) of its linear space of scenes. in practice, the image is a pattern on a cathode-ray tube, an aerial photograph, an engineer's or architect's drawing, or an x-ray or nmr scan. the rank of its space of scenes will reveal whether there is ambiguity or uniqueness in the construction of its spatial interpretation, or whether such a construction is in fact impossible, as would be the case for a poorly conceived engineering drawing, or even in an otherwise correctly conceived drawing, if too many hypotheses are made concerning the 3d structure of the scene. calculation of the rank of the space of scenes having a given image should, in principle, be accomplished using simple combinatorial algorithms based on easily-remembered rules-of-thumb. this is the goal, and it shows every sign of being achievable. the problem has, however, a certain degree of unavoidable difficulty. the requirement that a given image be an accurate projection of a non-trivial (non-planar) 3d scene imposes conditions on the image, conditions which are perhaps best described in terms of not-always-elementary constructions with straight-edge and pencil. in this paper, we begin to sort out the interplay of these projective conditions by creating a new homology theory for geometric configurations. the new homology theory applies to geometric objects which are more rigid, less pliable, than the rubber sheets studied by the topology of henri poincar and his school. the passage to this higher degree of invariance is made possible by the creation of a homology theory with (restricted) vector, rather than (unrestricted) scalar, coefficients, or equivalently, by the use of a cohomology theory based on locally linear, rather than on locally constant, functions. we have verified that the new theory agrees with the cohomology theory for the sheaf of locally linear functions on a certain (combinatorially defined) topological space. the basic objects about which this new homology theory has something non-trivial to say are extremely general. from the geometric point of view, they are simply finite sets of points in a projective space or finite sets of vectors in a vector space. in order to emphasize the departure we take from linear algebra as it is usually practiced, we should say that we study vector spaces with a selected basis , that is, concrete vector spaces , in their usual representation as spaces f p of functions from a set p into a field f. finally, we might say we are simply studying rectangular matrices . since such objects are found throughout applied mathematics, the resulting homology theory has a very broad range of potential application. indeed, potential applications of this new homology theory are to any domain where one is interested in the global behavior of systems determined locally by linear constraints.\", [u'requirements', u'point', u'sorting', u'applications', u'geometry', u'mathematics', u'use', u'invariance', u'analysis', u'linear algebra', u'project', u'theory', u'timing', u'graphics', u'group', u'representation', u'paper', u'constraint', u'automation', u'informal', u'scan', u'spatial', u'research', u'method', u'behavior', u'packaging', u'sketching', u'configurability', u'3d', u'image', u'algorithm', u'algebra', u'rules', u'global', u'tools', u'help', u'order', u'drawing', u'ambiguities', u'engine', u'computation', u'object', u'topologies', u'case', u'general', u'practical', u'pattern', u'observability', u'software', u'structure', u'vectorization', u'systems', u'space', u'interpretation', u'ranking'])\n",
      "(u'imagesense: towards contextual image advertising', u'the daunting volumes of community-contributed media contents on the internet have become one of the primary sources for online advertising. however, conventional advertising treats image and video advertising as general text advertising by displaying relevant ads based on the contents of the web page, without considering the inherent characteristics of visual contents. this article presents a contextual advertising system driven by images, which automatically associates relevant ads with an image rather than the entire text in a web page and seamlessly inserts the ads in the nonintrusive areas within each individual image. the proposed system, called imagesense, supports scalable advertising of, from root to node, web sites, pages, and images. in imagesense, the ads are selected based on not only textual relevance but also visual similarity, so that the ads yield contextual relevance to both the text in the web page and the image content. the ad insertion positions are detected based on image salience, as well as face and text detection, to minimize intrusiveness to the user. we evaluate imagesense on a large-scale real-world images and web pages, and demonstrate the effectiveness of imagesense for online image advertising.', [u'algorithms', u'experimentation', u'human factors'])\n",
      "(u'construction and blind estimation of phase sequences for subcarrier-phase control based papr reduction in ldpc coded ofdm systems', u'as described in this paper construction and blind estimation methods of phase sequences are proposed for subcarrier phase control based peak to average power ratio (papr) reduction in low density parity check (ldpc) coded orthogonal frequency division multiplexing (ofdm) systems. on the transmitter side phase sequence patterns are constructed based on a given parity check matrix. the papr of the ofdm signal is reduced by multiplying the constructed phase sequence selected from the same number of candidates as the number of weighting factor (wf) combinations in a partial transmit sequence (pts) method. on the receiver side the phase sequence is estimated blindly using the decoding function i e the most likely phase sequence among a limited number of possible phase sequence candidates is inferred by comparing the sum product calculation results of each candidate. computer simulation results show that papr of qpsk ofdm and 16qam ofdm signals can be reduced respectively by about 3 7 db and 4 0 db without marked degradation of the block error rate (bler) performance as compared to perfect estimation in an attenuated 12 path rayleigh fading condition.', [u'ofdm', u'peak to average power ratio ', u'papr reduction', u'ldpc code'])\n",
      "(u'mathsat: tight integration of sat and mathematical decision procedures', u'recent improvements in propositional satisfiability techniques (sat) made it possible to tackle successfully some hard real-world problems (e.g., model-checking, circuit testing, propositional planning) by encoding into sat. however, a purely boolean representation is not expressive enough for many other real-world applications, including the verification of timed and hybrid systems, of proof obligations in software, and of circuit design at rtl level. these problems can be naturally modeled as satisfiability in linear arithmetic logic (lal), that is, the boolean combination of propositional variables and linear constraints over numerical variables. in this paper we present mathsat, a new, sat-based decision procedure for lal, based on the (known approach) of integrating a state-of-the-art sat solver with a dedicated mathematical solver for lal. we improve mathsat in two different directions. first, the top-level line procedure is enhanced and now features a tighter integration between the boolean search and the mathematical solver. in particular, we allow for theory-driven backjumping and learning, and theory-driven deduction; we use static learning in order to reduce the number of boolean models that are mathematically inconsistent; we exploit problem clustering in order to partition mathematical reasoning; and we define a stack-based interface that allows us to implement mathematical reasoning in an incremental and backtrackable way. second, the mathematical solver is based on layering; that is, the consistency of (partial) assignments is checked in theories of increasing strength (equality and uninterpreted functions, linear arithmetic over the reals, linear arithmetic over the integers). for each of these layers, a dedicated (sub)solver is used. cheaper solvers are called first, and detection of inconsistency makes call of the subsequent solvers superfluous. we provide a through experimental evaluation of our approach, by taking into account a large set of previously proposed benchmarks. we first investigate the relative benefits and drawbacks of each proposed technique by comparison with respect to a reference option setting. we then demonstrate the global effectiveness of our approach by a comparison with several state-of-the-art decision procedures. we show that the behavior of mathsat is often superior to its competitors, both on lal and in the subclass of difference logic.', [u'satisfiability module theory', u'integrated decision procedures', u'linear arithmetic logic', u'propositional satisfiability'])\n",
      "(u'strongly regular graphs with the (7)-vertex condition', u'the (t)-vertex condition, for an integer (tge 2), was introduced by hestenes and higman (siam am math soc proc 4:41160, 1971) providing a combinatorial invariant defined on edges and non-edges of a graph. finite rank 3 graphs satisfy the condition for all values of (t). moreover, a long-standing conjecture of klin asserts the existence of an integer (t_0) such that a graph satisfies the (t_0)-vertex condition if and only if it is a rank 3 graph. we present the first infinite family of non-rank 3 strongly regular graphs satisfying the (7)-vertex condition. this implies that the klin parameter (t_0) is at least 8. the examples are the point graphs of a certain family of generalized quadrangles.', [u'strongly regular graph', u't-vertex condition', u'generalized quadrangle'])\n",
      "(u'((epsilon )-)efficiency in difference vector optimization', u'the paper deals with the problem of characterizing pareto optima (efficient solutions) for the difference of two mappings vector-valued in a finite or infinite-dimensional preordered space. closely related to the well-known optimality criterion of scalar dc optimization, a mixed vectorial condition is obtained in terms of both strong (fenchel) and weak (pareto) (epsilon )-subdifferentials that completely characterizes the exact or approximate weak efficiency. this condition also allows to deal with some special restricted mappings. moreover, the condition established in the literature in terms of strong (epsilon )-subdifferentials for characterizing the strongly efficient solutions (usual optima), is shown here to remain valid without assuming that the objective space is order-complete.', [u'vector optimization', u'dc objective', u'efficiency', u'optimality criteria', u'-solutions', u'vector -subdifferentials'])\n",
      "(u'iterative visual clustering for unstructured text mining', u\"this paper proposes the iterative visual clustering (ivc) on unstructured text sequences to form and evaluate keyword clusters, based on which users can use visual analysis, domain knowledge to discover knowledge in the text. the text sequence data are broken down into a list representative keywords after textual evaluation, and the keywords are then grouped to form keyword clusters via an iterative stochastic process and are visualized as distributions over the time lines. the visual evaluation model provides shape evaluations as quantitative tools and users' interactions as qualitative tools to visually investigate the trends, patterns represented by the keyword clusters' distributions. the keyword clustering model, guided by the feedback of visual evaluations, step-wisely enumerates newer generations of keyword clusters and their patterns, therefore narrows down the search space. then the proposed ivc is applied onto nursing narratives and is able to identify interesting keyword clusters implying hidden knowledge regarding to the working patterns and environment of registered nurses. the loop of producing next generation of keyword clusters in ivc is driven and controlled by users' perception, domain knowledge and interactions, and it is also guided by a stochastic search model. so both semantic and distribution features enable ivc to have significant applications as a text mining tool, on many other data sets, such as biomedical literatures.\", [u'text and document visualization', u'nursing data processing'])\n",
      "(u'economic growth, telecommunications development and productivity growth of the telecommunications sector: evidence around the world', u'this paper studies the relationships between economic growth, telecommunications development and productivity growth of the telecommunications sector in different countries and regions of the world. in particular, this study assesses the impact of mobile telecommunications on economic growth and telecommunications productivity. the results indicate that there is a bidirectional relationship between real gross domestic product (gdp) and telecommunications development (as measured by teledensity) for european and high-income countries. however, when the impact of mobile telecommunications development on economic growth is measured separately, the bi-directional relationship is no longer restricted to european and high-income countries. this study also finds that countries in the upper-middle income group have achieved a higher average total factor productivity (tfp) growth than other countries. countries with competition and privatization in telecommunications have achieved a higher tfp growth than those without competition and privatization. the diffusion of mobile telecommunications services is found to be a significant factor that has improved the tfp growth of the telecommunications sector in central and eastern europe (cee).', [u'telecommunications', u'economic growth', u'total factor productivity'])\n",
      "(u'examining learning from text and pictures for different task types: does the multimedia effect differ for conceptual, causal, and procedural tasks', u'the multimedia effect (me) is a well-researched effect in the field of learning and instruction. in this article, two views that explain the me are compared. the outcome-oriented view focuses on the beneficial effect of text and pictures on mental representations, whereas the process-oriented view focuses on the beneficial effect of text and pictures for information processing. to contrast these views, the me sizes for different task types were compared (i.e., conceptual, causal, procedural tasks). whereas the outcome-oriented view predicts no differences in me size, the process-oriented view predicts that the me is largest in causal tasks, smaller in procedural tasks, and smallest in conceptual tasks. sixty-five students learnt with text only or with text and pictures. task type and information source (i.e., whether the text, picture, or text and picture provided the answer to a post-test question) were varied within subjects. the results showed that, in line with the process-oriented view, the me was smaller for conceptual tasks than for procedural tasks. contrary to the expectations, the me was larger in procedural tasks than in causal tasks. moreover, the pattern of results varied with information source. research and practical implications are described, so that pictures can be deployed optimally.', [u'learning with text and pictures', u'multimedia effect', u'conceptual', u'causal and procedural tasks', u'static visualisations'])\n",
      "(u\"sufficient conditions for lambda '-optimality of graphs with small conditional diameter\", u\"a restricted edge-cut s of a connected graph g is an edge-cut such that g - s has no isolated vertex. the restricted edge-connectivity lambda'(g) is the minimum cardinality over all restricted edge-cuts. a graph is said to lambda'-optimal if lambda'(g) = xi(g), where xi(g) denotes the minimum edge-degree of g defined as xi(g) = min{d(u) + d(nu) - 2: u nu is an element of e(g)}. the p-diameter of g measures how far apart a pair of subgraphs satisfying a given property p can be, and hence it generalizes the standard concept of diameter. in this paper we prove two kind of results, according to which property p is chosen. first, let d-1 (resp. d-2) be the p-diameter where p is the property that the corresponding subgraphs have minimum degree at least one (resp. two). we prove that a graph with odd girth g is lambda'-optimal if d-1  = 2, being the minimum degree of g. using the property q of being vertices of g - f we prove that a graph with girth g is not an element of {4, 6, 8} is lambda'-optimal if this q-diameter is at most 2[(g - 3)/2].  \", [u'fault tolerance', u'restricted edge-connectivity', u'conditional diameter'])\n",
      "(u'comparative analysis of clicks and judgments for ir evaluation', u'queries and click-through data taken from search engine transaction logs is an attractive alternative to traditional test collections, due to its volume and the direct relation to end-user querying. the overall aim of this paper is to answer the question: how does click-through data differ from explicit human relevance judgments in information retrieval evaluation? we compare a traditional test collection with manual judgments to transaction log based test collections---by using queries as topics and subsequent clicks as pseudo-relevance judgments for the clicked results. specifically, we investigate the following two research questions: firstly, are there significant differences between clicks and relevance judgments. earlier research suggests that although clicks and explicit judgments show reasonable agreement, clicks are different from static absolute relevance judgments. secondly, are there significant differences between system ranking based on clicks and based on relevance judgments? this is an open question, but earlier research suggests that comparative evaluation in terms of system ranking is remarkably robust.', [u'transaction log analysis', u'wikipedia', u'web information retrieval'])\n",
      "(u's2-quasicontinuous posets', u'in this paper, we consider a common generalization of both s2-continuous posets and quasicontinuous domains, and we introduce new concepts of way below relations and s2-quasicontinuous posets. the main results are: (1) the way below relation on an s2-quasicontinuous poset has the interpolation property; (2) the 2-topology on an s2-quasicontinuous poset is completely regular; (3) a poset is s2-continuous iff it is meet s2-continuous and s2-quasicontinuous.', [u's2-continuous poset', u'meet s2-continuous poset s2', u's2-quasicontinuous poset s2', u'-topology'])\n",
      "(u'does the polynomial hierarchy collapse if onto functions are invertible', u'the class tfnp, defined by megiddo and papadimitriou, consists of multivalued functions with values that are polynomially verifiable and guaranteed to exist. do we have evidence that such functions are hard, for example, if tfnp is computable in polynomial-time does this imply the polynomial-time hierarchy collapses? by computing a multivalued function in deterministic polynomial-time we mean on every input producing one of the possible values of the function on that input. we give a relativized negative answer to this question by exhibiting an oracle under which tfnp functions are easy to compute but the polynomial-time hierarchy is infinite. we also show that relative to this same oracle, p not equal up and tfnp(np) functions are not computable in polynomial-time with an np oracle.', [u'computational complexity', u'polynomial-time hierarchy', u'multi-valued functions', u'kolmogorov complexity'])\n",
      "(u'unsupervised object segmentation with a hybrid graph model (hgm)', u'in this work, we address the problem of performing class-specific unsupervised object segmentation, i.e., automatic segmentation without annotated training images. object segmentation can be regarded as a special data clustering problem where both class-specific information and local texture/color similarities have to be considered. to this end, we propose a hybrid graph model (hgm) that can make effective use of both symmetric and asymmetric relationship among samples. the vertices of a hybrid graph represent the samples and are connected by directed edges and/or undirected ones, which represent the asymmetric and/or symmetric relationship between them, respectively. when applied to object segmentation, vertices are superpixels, the asymmetric relationship is the conditional dependence of occurrence, and the symmetric relationship is the color/texture similarity. by combining the markov chain formed by the directed subgraph and the minimal cut of the undirected subgraph, the object boundaries can be determined for each image. using the hgm, we can conveniently achieve simultaneous segmentation and recognition by integrating both top-down and bottom-up information into a unified process. experiments on 42 object classes (9,415 images in total) show promising results.', [u'segmentation', u'graph-theoretic methods', u'spectral clustering'])\n",
      "(u'dispersion free wave splittings for structural elements', u'wave splittings are derived for three types of structural elements: membranes, timoshenko beams, and mindlin plates. the timoshenko beam equation and the mindlin plate equation are inherently dispersive, as is each fourier component of the membrane equation in an angular decomposition of the field. the distinctive feature of the wave splittings derived in the present paper is that, in homogeneous regions, they transform the dispersive wave equations into simple one-way wave equations without dispersion. such splittings have uses both for radial scattering problems in the 2d cases and for scattering problems in dispersive media. as an example of how the splittings may be applied, a direct scattering problem is solved for a membrane with radially varying density. the imbedding method is utilized, and agreement is obtained with an fe simulation.', [u'wave splitting', u'time domain methods', u'greens operator', u'imbedding', u'membrane', u'timoshenko beam', u'mindlin plate'])\n",
      "(u'designing a practical data filter cache to improve both energy efficiency and performance', u'conventional data filter cache (dfc) designs improve processor energy efficiency, but degrade performance. furthermore, the single-cycle line transfer suggested in prior studies adversely affects level-1 data cache (l1 dc) area and energy efficiency. we propose a practical dfc that is accessed early in the pipeline and transfers a line over multiple cycles. our dfc design improves performance and eliminates a substantial fraction of l1 dc accesses for loads, l1 dc tag checks on stores, and data translation lookaside buffer accesses for both loads and stores. our evaluation shows that the proposed dfc can reduce the data access energy by 42.5% and improve execution time by 4.2%.', [u'speculation', u'filter cache'])\n",
      "(u'analytical model for anomalous positive bias temperature instability in la-based hfo2 nfets based on independent characterization of charging components', u'pbti improvement in hfo2 nfets achieved by a controlled insertion of la. anomalous negative ?vth due to charge exchange between high-k and metal gate. anomalous and conventional pbti components are decoupled and studied separately. analytical model including both components for lifetime extrapolation is presented.', [u'metaloxidesemiconductor field-effect transistor ', u'bias temperature instability', u'hafnium oxide', u'silicon oxide'])\n",
      "(u'a social behaviour evolution approach for evolutionary optimisation', u'evolutionary algorithms were originally designed to locate basins of optimum solutions in a stationary environment. therefore, additional techniques and modifications have been introduced to deal with further requirements such as handling dynamic fitness functions or finding multiple optima. in this paper, we present a new approach for building evolutionary algorithms that is based on concepts borrowed from social behaviour evolution. algorithms built with the proposed paradigm operate on a population of individuals that move in the search space as they interact and form groups. the interaction follows a set of social behaviours evolved by each group to enhance its adaptation to the environment (and other groups) and to achieve different desirable goals such as finding multiple optima, maintaining diversity, or tracking a moving peak in a changing environment. each group has two sets of behaviours: one for intra-group interactions and one for inter-group interactions. these behaviours are evolved using mathematical models from the field of evolutionary game theory. this paper describes the proposed paradigm and starts studying it characteristics by building a new evolutionary algorithm and studying its behavior. the algorithm has been tested using a benchmark problem generator with promising initial results, which are also reported.', [u'social behaviour evolution', u'social adaptive groups', u'evolutionary optimisation', u'evolutionary game theory', u'evolutionary algorithms', u'dynamic optimisation problems'])\n",
      "(u'planar c1 hermite interpolation with ph cuts of degree (1,3) of laurent series', u'we introduce a new class of ph curves, ph cuts of degree (1,3)  of laurent series. we show how to find ph skew cut interpolants to a c1 hermite data-set. we show that two of these interpolants are short, simple curves with stable shape. our curves are fair with different shapes to those of other interpolants. we can obtain regular ph interpolants for collinear c1 hermite data-sets.', [u'pythagorean hodograph  curve', u'c1 hermite interpolation', u'complex representation', u'cut of degree of a laurent series', u'ph skew cut', u'ph skew cut interpolant'])\n",
      "(u'bicepstrum based blind identification of the acoustic emission (ae) signal in precision turning', u'it is believed that the acoustic emissions (ae) signal contains potentially valuable information for monitoring precision cutting processes, as well as to be employed as a control feedback signal. however, ae stress waves produced in the cutting zone are distorted by the transmission path and the measurement systems. in this article, a bicepstrum based blind system identification technique is proposed as a valid tool for estimating both, transmission path and sensor impulse response. assumptions under which application of bicepstrum is valid are discussed and diamond turning experiments are presented, which demonstrate the feasibility of employing bicepstrum for ae blind identification.', [u'acoustic emissions', u'higher-order statistics', u'blind identification', u'precision machining'])\n",
      "(u'on solving hierarchical problems with top down control', u'we review recent work on the hierarchical-if-and-only-if problem and present a new hierarchical problem, hiff-m that does not fit with previous explanations for evolutionary difficulty on hierarchical problems decomposed by levels for rmhc2. rmhc2 is a hill climbing algorithm augmented with a multi-level selection scheme. when used with the \"ideal\" sieve for a problem, as is done in this paper, rmhc2 exerts top-down control on the evolutionary dynamics, in the sense that adaptation of higher levels are given priority over adaptation of lower levels, and creates stabilizing selection pressure with potential to increase evolvability. through hiff-m, we discovered that the summary statistic, fitness distance correlation by level, is not a reliable indicator of when a hierarchical problem is solvable by rmhc2, and that the two properties proposed to explain search easiness for rmhc2 are inadequate. our investigation of this anomaly led us to propose an additional property for hierarchical evolution difficulty under rmhc2: inter-level conflict. we also discuss how hierarchical control can be subverted through the information transfer capacity of the transposition operation.', [u'hierarchical test problems', u'hierarchical control', u'level decomposition', u'transposition'])\n",
      "(u'extracting semantic frames from thai medical-symptom unstructured text with unknown target-phrase boundaries', u'due to the limitations of language-processing tools for the thai language, pattern-based information extraction from thai documents requires supplementary techniques. based on sliding-window rule application and extraction filtering, we present a framework for extracting semantic information from medical-symptom phrases with unknown boundaries in thai unstructured-text information entries. a supervised rule learning algorithm is employed for automatic construction of information extraction rules from hand-tagged training symptom phrases. two filtering components are introduced: one uses a classification model to predict rule application across a symptom-phrase boundary based on instantiation features of rule internal wildcards, the other uses weighted classification confidence to resolve conflicts arising from overlapping extractions. in our experimental study, we focus our attention on two basic types of symptom phrasal descriptions: one is concerned with abnormal characteristics of some observable entities and the other with human-body locations at which primitive symptoms appear. the experimental results show that the filtering components improve precision while preserving recall satisfactorily.', [u'information extraction', u'medical informatics', u'rule learning'])\n",
      "(u'robust doa estimation for uncorrelated and coherent signals', u'a new direction of arrival (doa) estimation method is introduced with arbitrary array geometry when uncorrelated and coherent signals coexist. the doas of uncorrelated signals are first estimated via subspace-based high resolution doa estimation technique. then a matrix that only contains the information of coherent signals can be formulated by eliminating the contribution of uncorrelated signals. finally a subspace block sparse reconstruction approach is taken for doa estimations of the coherent signals.', [u'coherent signals', u'direction of arrival', u'sparse reconstruction'])\n",
      "(u'checkpoint allocation and release', u'out-of-order speculative processors need a bookkeeping method to recover from incorrect speculation. in recent years, several microarchitectures that employ checkpoints have been proposed, either extending the reorder buffer or entirely replacing it. this work presents an in-dept-study of checkpointing in checkpoint-based microarchitectures, from the desired content of a checkpoint, via implementation trade-offs, and to checkpoint allocation and release policies. a major contribution of the article is a novel adaptive checkpoint allocation policy that outperforms known policies. the adaptive policy controls checkpoint allocation according to dynamic events, such as second-level cache misses and rollback history. it achieves 6.8% and 2.2% speedup for the integer and floating point benchmarks, respectively, and does not require a branch confidence estimator. the results show that the proposed adaptive policy achieves most of the potential of an oracle policy whose performance improvement is 9.8% and 3.9% for the integer and floating point benchmarks, respectively. we exploit known techniques for saving leakage power by adapting and applying them to checkpoint-based microarchitectures. the proposed applications combine to reduce the leakage power of the register file to about one half of its original value.', [u'design', u'performance', u'checkpoint', u'misprediction', u'out-of-order execution', u'rollback', u'early register release', u'leakage'])\n",
      "(u'a quadratic spline approximation using detail multi-layer for soft shadow generation in augmented reality', u'implementation of shadows is crucial to enhancement of images in ar environments. without shadows, virtual objects would look floating over the scene resulting in unrealistic rendering of ar environments. casting hard shadows would provide only spatial information while soft shadows help improve realism of ar environments. several algorithms have been proposed to render realistic shadows which often incurred high computational costs. little attention has been directed towards the balanced trade-off between shadow quality and computational costs. in this study, two approaches are proposed: quadratic spline interpolation (qsi) to soften the outline of the shadow and detail multi-layer (dml) technique to optimize the volume of computations for the generation of soft shadows based on real light sources. qsi estimates boarder hard shadow samples while dml involves three main phases: real light sources estimation, soft shadow production and reduction of the complexity of 3-dimensional objects shadows. to be more precise, a reflective hemisphere is used to capture real light and to create an environment map. the median cut algorithm is implemented to locate the direction of real light sources on the environment map. subsequently, the original hard shadows are retrieved and a sample of multilayer hard shadows is produced where each layer has its unique size and colour. these layers overlap to produce soft shadows based on the real light sources directions. finally, the level of details (lod) algorithm is implemented to increase the efficiency of soft shadows by decreasing the complexity of vertex transformations. the proposed technique is tested using three samples of multilayer hard shadows with varying numbers of light sources generated from the median cut algorithm. the experimental results show that the proposed technique successfully produces realistic soft shadows at low computational costs.', [u'augmented reality', u'shadow generation', u'soft shadows', u'reflective sphere', u'environment map'])\n",
      "(u'the enhanced optical coupling in a quantum well infrared photodetector based on a resonant mode of an airdielectricmetal waveguide', u'the hybrid structure consisting of periodic gold stripes and an overlaying gold film is proposed to enhance the optical coupling of a quantum well infrared photodetector. an airdielectricmetal waveguide is formed when the hybrid structure is integrated on the top of the quantum well detector with the substrate being removed. finite difference time-domain method is used to numerically obtain the reflection spectrum and the field distribution of the waveguide. the results show that a strong electric field component is induced in parallel to the growth direction of quantum well when the waveguide resonant mode occurs at the detective wavelength of the quantum well infrared photodetector. the relationship between the structural parameters and the resonant wavelength is derived by using the effective refractive index method of the airdielectricmetal waveguide. a high coupling efficiency can be obtained and the performance of the qwip can be greatly improved.', [u'periodic gold stripes', u'quantum well infrared photodetector', u'airdielectricmetal waveguide resonance', u'effective refractive index', u'coupling efficiency'])\n",
      "(u'redirection based recovery for mpls network systems', u'to provide a reliable backbone network, fault tolerance should be considered in the network design. for a multiprotocol label switching (mpls) based backbone network, the fault-tolerant issue focuses on how to protect the traffic of a label switched paths (lsp) against node and link failures. in ietf, two well-known recovery mechanisms (protection switching and rerouting) have been proposed. to further enhance the fault-tolerant performance of the two recovery mechanisms, the proposed approach utilizes the failure-free lsps to transmit the traffic of the failed lsp (the affected traffic). to avoid affecting the original traffic of each failure-free lsp, the proposed approach applies the solution of the minimum cost flow to determine the amount of affected traffic to be transmitted by each failure-free lsp. for transmitting the affected traffic along a failure-free working lsp, ip tunneling technique is used. we also propose a permission token scheme to solve the packet disorder problem. finally, simulation experiments are performed to show the effectiveness of the proposed approach.', [u'mpls', u'fault tolerance', u'label switched path', u'affected traffic', u'minimum cost flow'])\n",
      "(u'designing a cross-language comparison-shopping agent', u\"this research pertains to the design and development of a shopbot called webshopper+. this shopbot is intended to help customers find and compare e-tailers that market their wares using different languages. webshopper+ is built with a multilingual ontology to overcome the language barriers that arise with global e-commerce. this research proposes a semi-automatic method of constructing a multilingual ontology by using the formal concept analysis and association analysis. it also proposes an automatic method for the categorization of product data into predefined classes, with the aim of alleviating administrators' task load. additionally, a semantic search mechanism based on concept similarity is designed to assist customers in finding more desirable products. the experimental results show that these methods perform well and the shopbot can help customers find real bargains on the web and to find products that cannot be bought locally.\", [u'shopbot', u'comparison-shopping', u'ontology', u'semantic similarity', u'formal concept analysis'])\n",
      "(u'medical informaticsthe state of the art in the hospital authority', u'since its inception in 1990, the hospital authority (ha) has strongly supported the development and implementation of information systems both to improve the delivery of care and to make better information available to managers. this paper summarizes the progress to date and discusses current and future developments. following the first two phases of the ha information technology strategy the basic infrastructural elements were laid in place. these included the foundation administrative and financial systems and databases; establishment of a wide area network linking all hospitals and clinics together; laboratory, radiology and pharmacy systems with access to results in the ward. a major push into clinical systems began in 1994 with the clinical management system (cms), which established a clinical workstation for use in both ward and ambulatory settings. the cms is now running at all major hospitals, and provides single logon access to almost all the electronically collected clinical data in the ha. the next phase of development is focussed on further support for clinical activities in the cms. key elements include the longitudinal electronic patient record (epr), clinical order entry, generic support for clinical reports, broadening the scope to include allied health and the rehabilitative phase, clinical decision support, an improved clinical documentation framework, sharing of clinical information with other health care providers and a comprehensive data repository for analysis and reporting purposes.', [u'hospital information systems', u'clinical information systems', u'hong kong'])\n",
      "(u'prioritization of potential candidate disease genes by topological similarity of proteinprotein interaction network and phenotype data', u'we construct a reliable heterogeneous network by fusing multiple networks. we devise a random walk based algorithm on the reliable heterogeneous network. combining topological similarity with phenotype data helps to predict causal genes. the algorithm is still in good performance at low parameter values.', [u'disease genes', u'random walk', u'topological similarity', u'proteinprotein interaction networks', u'phenotype'])\n",
      "(u'extended beta regression in r: shaken, stirred, mixed, and partitioned', u'beta regression -an increasingly popular approach for modeling rates and proportions - is extended in various directions: (a) bias correction/reduction of the maximum likelihood estimator, (b) beta regression tree models by means of recursive partitioning, (c) latent class beta regression by means of finite mixture models. all three extensions may be of importance for enhancing the beta regression toolbox in practice to provide more reliable inference and capture both observed and unobserved/latent heterogeneity in the data. using the analogy of smithson and verkuilen (2006), these extensions make beta regression not only \"a better lemon squeezer\" (compared to classical least squares regression) but a full-fledged modern juicer offering lemon-based drinks: shaken and stirred (bias correction and reduction), mixed (finite mixture model), or partitioned (tree model). all three extensions are provided in the r package betareg (at least 2.4-0), building on generic algorithms and implementations for bias correction/reduction, model-based recursive partioning, and finite mixture models, respectively. specifically, the new functions betatree () and betamix () reuse the object-oriented flexible implementation from the r packages party and flexmix, respectively.', [u'beta regression', u'bias correction', u'bias reduction', u'recursive partitioning', u'finite mixture', u'r'])\n",
      "(u'four-layer framework for combinatorial optimization problems domain', u'four-layer framework for combinatorial optimization problems/models domain is suggested for applied problems structuring and solving: (1) basic combinatorial models and multicriteria decision making problems (e.g., clustering, knapsack problem, multiple choice problem, multicriteria ranking, assignment/allocation); (2) composite models/procedures (e.g., multicriteria combinatorial problems, morphological clique problem); (3) basic (standard) solving frameworks, e.g.: (i) hierarchical morphological multicriteria design (hmmd) (ranking, combinatorial synthesis based on morphological clique problem), (ii) multi-stage design (two-level hmmd), (iii) special multi-stage composite framework (clustering, assignment/location, multiple choice problem); and (4) domain-oriented solving frameworks, e.g.: (a) design of modular software, (b) design of test inputs for multi-function system testing, (c) combinatorial planning of medical treatment, (d) design and improvement of communication network topology, (e) multi-stage framework for information retrieval, (f) combinatorial evolution and forecasting of software, devices. the multi-layer approach covers decision cycle, i.e., problem statement, models, algorithms/procedures, solving schemes, decisions, decision analysis and improvement.', [u'problem solving environment', u'system architecture', u'combinatorial optimization', u'decision making', u'problem structuring', u'system design'])\n",
      "(u'computing monodromy via continuation methods on random riemann surfaces', u'we consider a riemann surface x defined by a polynomial f (x, y) of degree d, whose coefficients are chosen randomly. hence, we can suppose that x is smooth, that the discriminant delta(x) of f has d(d - 1) simple roots, delta, and that delta(0) not equal 0, i.e. the corresponding fiber has d distinct points {y(1), ..., y(d)}. when we lift a loop 0 is an element of gamma subset of c - delta by a continuation method, we get d paths in x connecting {y(1), ..., y(d)}, hence defining a permutation of that set. this is called monodromy. here we present experimentations in maple to get statistics on the distribution of transpositions corresponding to loops around each point of delta. multiplying families of \"neighbor\" transpositions, we construct permutations and the subgroups of the symmetric group they generate. this allows us to establish and study experimentally two conjectures on the distribution of these transpositions and on transitivity of the generated subgroups. assuming that these two conjectures are true, we develop tools allowing fast probabilistic algorithms for absolute multivariate polynomial factorization, under the hypothesis that the factors behave like random polynomials whose coefficients follow uniform distributions.  ', [u'bivariate polynomial', u'plane curve', u'random riemann surface', u'absolute factorization', u'algebraic geometry', u'continuation methods', u'monodromy', u'symmetric group', u'algorithms', u'maple code'])\n",
      "(u'feature-based decision aggregation in modular neural network classifiers', u'in several modular neural network (mnn) architectures, the individual decisions at the module level have to be integrated together using a voting scheme. all these voting schemes use the outputs of the individual modules to produce a global output without inferring explicit information from the problem feature space. this makes the choice of the aggregation procedure very subjective. in this work, a new mnn architecture will be presented. this architecture integrates learning into the voting scheme. we will be focusing on making the decision fusion a more dynamic process. in this context, dynamic means the aggregation procedure which has the flexibility to adapt to changes in the input. this approach requires the aggregation procedure to gather information about the input to help better understand how to dynamically aggregate decisions.', [u'classification', u'classifier combination', u'dynamic decision fusion', u'modular neural networks'])\n",
      "(u'efficient bootstrap with weakly dependent processes', u'the efficient bootstrap methodology is developed for overidentified moment conditions models with weakly dependent observation. the resulting bootstrap procedure is shown to be asymptotically valid and can be used to approximate the distributions of t-statistics, the j-statistic for overidentifying restrictions, and wald, lagrange multiplier and distance statistics for nonlinear hypotheses. the asymptotic validity of the efficient bootstrap based on a computationally less demanding approximate k-step estimator is also shown. the finite sample performance of the proposed bootstrap is assessed using simulations in an intertemporal consumption based asset pricing model.', [u'alpha-mixing', u'consumption capm', u'gel', u'gmm', u'hypothesis testing'])\n",
      "(u'multi-relay cooperative diversity protocol with improved spectral efficiency', u'cooperative diversity protocols have attracted a great deal of attention since they are thought to be capable of providing diversity multiplexing tradeoff among single antenna wireless devices. in the high signal to noise ratio (snr) region, cooperation is rarely required; hence, the spectral efficiency of the cooperative protocol can be improved by applying a proper cooperation selection technique. in this paper, we present a simple \"cooperation selection\" technique based on instantaneous channel measurement to improve the spectral efficiency of cooperative protocols. we show that the same instantaneous channel measurement can also be used for relay selection. in this paper two protocols are proposed-proactive and reactive; the selection of one of these protocols depends on whether the decision of cooperation selection is made before or after the transmission of the source. these protocols can successfully select cooperation along with the best relay from a set of available m relays. if the instantaneous source to destination channel is strong enough to support the system requirements, then the source simply transmits to the destination as a noncooperative direct transmission; otherwise, a cooperative transmission with the help of the selected best relay is chosen by the system. analysis and simulation results show that these protocols can achieve higher order diversity with improved spectral efficiency, i.e., a higher diversity-multiplexing tradeoff in a slow-fading environment.', [u'cooperative diversity', u'diversity-multiplexing tradeoff', u'fading channel', u'outage probability', u'relay selection', u'spectral efficiency'])\n",
      "(u'a motion-tolerant dissolve detection algorithm', u'gradual shot change detection is one of the most important research issues in the field of video indexing/retrieval. among the numerous types of gradual transitions, the dissolve-type gradual transition is considered the most common one, but it is also the most difficult one to detect. in most of the existing dissolve detection algorithms, the false/miss detection problem caused by motion is very serious. in this paper, we present a novel dissolve-type transition detection algorithm that can correctly distinguish dissolves from disturbance caused by motion. we carefully model a dissolve based on its nature and then use the model to filter out possible confusion caused by the effect of motion. experimental results show that the proposed algorithm is indeed powerful.', [u'dissolve detection', u'fade detection', u'shot change detection'])\n",
      "(u'gmm-based evaluation of emotional style transformation in czech and slovak', u'in the development of the voice conversion and the emotional speech style transformation in the text-to-speech systems, it is very important to obtain feedback information about the users opinion on the resulting synthetic speech quality. for this reason, the evaluations of the quality of the produced synthetic speech must often be performed for comparison. the main aim of the experiments described in this paper was to find out whether the classifier based on gaussian mixture models (gmms) could be applied for evaluation of male and female resynthesized speech that had been transformed from neutral to four emotional states (joy, surprise, sadness, and anger) spoken in czech and slovak languages. we suppose that it is possible to combine this gmm-based statistical evaluation with the classical one in the form of listening tests or it can replace them. for verification of our working hypothesis, a simple gmm emotional speech classifier with a one-level structure was realized. the next task of the performed experiment was to investigate the influence of different types and values (mean, median, standard deviation, relative maximum, etc.) of the used speech features (spectral and/or supra-segmental) on the gmm classification accuracy. the obtained gmm evaluation scores are compared with the results of the conventional listening tests based on the mean opinion scores. in addition, correctness of the gmm classification is analyzed with respect to the influence of the setting of the parameters during the gmm trainingthe number of mixture components and the types of speech features. the paper also describes the comparison experiment with the reference speech corpus taken from the berlin database of emotional speech in german language as the benchmark for the evaluation of the performance of our one-level gmm classifier. the obtained results confirm practical usability of the developed gmm classifier, so we will continue in this research with the aim to increase the classification accuracy and compare it with other approaches like the support vector machines.', [u'emotional speech transformation', u'spectral and prosodic features of speech', u'gmm-based emotion classification'])\n",
      "(u'collage of two-dimensional words', u'we consider a new operation on one-dimensional (resp. two-dimensional) word languages, obtained by piling up, one on top of the other, words of a given recognizable language (resp. two-dimensional recognizable language) on a previously empty one-dimensional (resp. two-dimensional) array. the resulting language is the set of words \"seen from above\": a position in the array is labeled by the topmost letter. we show that in the one-dimensional case, the language is always recognizable. this is no longer true in the two-dimensional case which is shown by a counter-example, and we investigate in which particular cases the result may still hold. ', [u'regular languages', u'picture languages'])\n",
      "(u'inference management, trust and obfuscation principles for quality of information in emerging pervasive environments', u'the emergence of large scale, distributed, sensor-enabled, machine-to-machine pervasive applications necessitates engaging with providers of information on demand to collect the information, of varying quality levels, to be used to infer about the state of the world and decide actions in response. in these highly fluid operational environments, involving information providers and consumers of various degrees of trust and intentions, information transformation, such as obfuscation, is used to manage the inferences that could be made to protect providers from misuses of the information they share, while still providing benefits to their information consumers. in this paper, we develop the initial principles for relating to inference management and the role that trust and obfuscation plays in it within the context of this emerging breed of applications. we start by extending the definitions of trust and obfuscation into this emerging application space. we, then, highlight their role as we move from the tightly-coupled to loosely-coupled sensory-inference systems and describe how quality, value and risk of information relate in collaborative and adversarial systems. next, we discuss quality distortion illustrated through a human activity recognition sensory system. we then present a system architecture to support an inference firewall capability in a publish/subscribe system for sensory information and conclude with a discussion and closing remarks.', [u'quality of information', u'value of information', u'risk of information', u'qoi', u'voi', u'roi', u'obfuscation', u'inference management'])\n",
      "(u'digging in the digg social news website', u'the rise of social media aggregating websites provides platforms where users can actively publish, evaluate, and disseminate content in a collaborative way. in this paper, we present a large-scale empirical study about \"digg.com\", one of the biggest social media aggregating websites. our analysis is based on crawls of 1.5 million users and 10 million published stories on digg. we study the distinct network structure, the collaborative user characteristics, and the content dissemination process on digg. we empirically illustrate that friendship relations are used effectively in disseminating half of the content, although there exists a high overlap between the interests of friends. a successful content dissemination process can also be performed by random users who are browsing and digging stories. since 88% of the published content on digg is defined as news, it is important for the content to obtain sufficient votes in a short period of time before becoming obsolete. finally, we show that the synchronization of users\\' activities in time is the key to a successful content dissemination process. the dynamics between users\\' voting activities consequently decrease the efficiency of friendship relations during content dissemination. the results presented in this paper define basic observations and measurements to understand the underlying mechanism of disseminating content in current online social news aggregators. these findings are helpful to understand the influence of service interfaces and user behaviors on content dissemination.', [u'content dissemination', u'friendship relations', u'social media website', u'user characteristics'])\n",
      "(u'usage of agents in document management', u'extensible java-based agent framework (xjaf) is a pluggable architecture of the hierarchical intelligent agents system with communication based on kqml. workers, inc. is a workflow management system implemented using mobile agents. it is especially suited for highly distributed and heterogeneous environments. the application of the above-mentioned systems will be considered in the area of document management systems.', [u'mobile agents', u'workflow management systems', u'document management'])\n",
      "(u'ezpal: environment for composing constraint axioms by instantiating templates', u'many ontology-development tools allow users to supplement frame-based representations with arbitrary logical sentences. however, few users actually take advantage of this opportunity. for example, in the ontolingua ontology library, only 20% of the ontologies have any user-defined axioms. we believe the difficulty of composing axioms primarily accounts for the lack of axioms in these knowledge bases: many domain experts cannot translate their thoughts into abstract and symbolic representations. we attempt to remedy the difficulties by identifying groups of axioms that manifest common patterns, creating templates that allow users to compose axioms by filling in the blanks. we studied axioms in two public ontology libraries, and derived 20 templates that cover 85% of all the user-defined axioms. we describe our methodology for identifying the templates and present examples. we constructed an interface that allows users to create constraints on knowledge bases by filling in blanks; our usability testing shows that users could use templates to encode axioms with a success rate similar to that of experts writing directly in an axiom language. our approach should foster the introduction of axioms and constraints that are currently missing in many ontologies.', [u'frame-based system', u'knowledge acquisition', u'knowledge representation'])\n",
      "(u'critical infrastructure dependencies: a holistic, dynamic and quantitative approach', u'the proper functioning of critical infrastructures is crucial to societal well-being. however, critical infrastructures are not isolated, but instead are tightly coupled, creating a complex system of interconnected infrastructures. dependencies between critical infrastructures can cause a failure to propagate from one critical infrastructure to other critical infrastructures, aggravating and prolonging the societal impact. for this reason, critical infrastructure operators must understand the complexity of critical infrastructures and the effects of critical infrastructure dependencies. however, a major problem is posed by the fact that detailed information about critical infrastructure dependencies is highly sensitive and is usually not publicly available. moreover, except for a small number of holistic and dynamic research efforts, studies are limited to a few critical infrastructures and generally do not consider time-dependent behavior. this paper analyzes how a failed critical infrastructure that cannot deliver products and services impacts other critical infrastructures, and how a critical infrastructure is affected when another critical infrastructure fails. the approach involves a holistic analysis involving multiple critical infrastructures while incorporating a dynamic perspective based on the time period that a critical infrastructure is non-operational and how the impacts evolve over time. this holistic approach, which draws on the results of a survey of critical infrastructure experts from several countries, is intended to assist critical infrastructure operators in preparing for future crises.', [u'critical infrastructure dependencies', u'holistic treatment', u'dynamic analysis', u'quantitative analysis'])\n",
      "(u'traffic distribution for end-to-end qos routing with multicast multichannel services', u'with the development of multimedia group applications and multicasting demands, the construction of multicast routing tree satisfying quality of service (qos) is more important. a multicast tree, which is constructed by existing multicast algorithms, suffers three major weaknesses: (1) it cannot be constructed by multichannel routing, transmitting a message using all available links, thus the data traffic cannot be preferably distributed; (2) it does not formulate duplication capacity; consequently, duplication capacity in each node cannot be optimally distributed; (3) it cannot change the number of links and nodes used optimally. in fact, it cannot employ and cover unused backup multichannel paths optimally. to overcome these weaknesses, this paper presents a polynomial time algorithm for distributed optimal multicast routing and quality of service (qos) guarantees in networks with multichannel paths which is called distributed optimal multicast multichannel routing algorithm (dommr). the aim of this algorithm is: (1) to minimize end-to-end delay across the multichannel paths, (2) to minimize consumption of bandwidth by using all available links, and (3) to maximize data rate by formulating network resources. dommr is based on the linear programming formulation (lpf) and presents an iterative optimal solution to obtain the best distributed routes for traffic demands between all edge nodes. computational experiments and numerical simulation results will show that the proposed algorithm is more efficient than the existing methods. the simulation results are obtained by applying network simulation tools such as qsb, opnet and matlb to some samples of network. we then introduce a generalized problem, called the delay-constrained multicast multichannel routing problem, and show that this generalized problem can be solved in polynomial time.', [u'multicasting', u'multichannel path', u'optimized routing', u'quality of services', u'traffic distribution', u'linear programming'])\n",
      "(u'improved error exponent for time-invariant and periodically time-variant convolutional codes', u'an improved upper bound on the error probability (first error event) of time-invariant convolutional codes, and the resulting error exponent, is derived ill this paper. the improved error bound depends on both the delay of the code k and its width (the number of symbols that enter the delay line in parallel) b. determining the error exponent of time-invariant convolutional codes is an open problem. while the previously known bounds on the error probability of time-invariant codes led to the block-coding exponent, obtain a better error exponent (strictly better for b > 1). in the limit b --> infinity our error exponent equals the yudkin-viterbi exponent derived for time-variant convolutional codes. these results are also used to derive an improved error exponent for periodically time-variant codes.', [u'convolutional codes', u'error exponent', u'error probability', u'periodically time-variant codes', u'time-invariant codes', u'yudkin-viterbi exponent'])\n",
      "(u'online reputation management for improving marketing by using a hybrid mcdm model', u'online reputation management (orm) has been considered as a significant tool of internet marketing. the purpose of this paper is to construct a decision model for evaluating performances and improving professional services of marketing. to investigate the interrelationship and influential weights among criteria, this study uses a hybrid mcdm model including decision-making trial and evaluation laboratory (dematel), dematel-based analytic network process (called danp). the empirical findings reveal that criteria have self-effect relationships based on dematel technique. according to the network relation map (nrm), the dimension that professional services of marketing should improve first when carrying out orm is online reputation. in the five criteria for evaluation, distributed reputation systems is the most important criterion impacting orm, followed by employees and social responsibility.', [u'online reputation management ', u'professional services of marketing', u'dematel', u'danp', u'mcdm'])\n",
      "(u'feasibility of a primarily digital research library', u'this position paper explores the issues related to the feasibility of having a primarily digital research library support the teaching and research needs of a university. the asian university for women (auw), a new university in chittagong, bangladesh, will open in september 2009. it must make a decision regarding the investment to be made in research resources to support the university. mass digitization efforts now make it possible to consider establishing a research library that consists primarily of digital resources rather than print. there are, however, many issues that make this consideration quite complex and far from certain. in this paper we explore the issues at a preliminary level. we focus on four broad perspectives in order to begin addressing the complex interactions that must be considered in transitioning to a primarily digital research environment: technical, economic, policy and social issues. the purpose of this paper is to begin to explore a research agenda for transitioning from a model for libraries where resources are primarily print to one that is predominantly digital. our research in this area is just beginning, so our purpose is to raise the issues rather than offer firm conclusions.', [u'digital libraries', u'libraries', u'digital research', u'mass digitization'])\n",
      "(u'targeting multiple myeloma cells and their bone marrow microenvironment', u'although multiple myeloma (mm) is sensitive to chemotherapy and radiation therapy, long-term disease-free survival is rare, and mm remains incurable despite conventional and high-dose therapies. direct (cell-cell contact) and soluble (via cytokines) forms of interactions between mm cells and bone marrow stroma regulate growth, survival, and homing of mm cells. these interactions also play a critical role in angiogenesis and in myeloma bone disease. in recent years, several studies have established the biologic significance of cytokines in mm pathogenesis and delineated signaling cascades mediating their effects, providing the framework for related novel therapies targeting not only the mm cell, but also the bone marrow microenvironment.', [u'multiple myeloma', u'bone marrow microenvironment', u'novel therapies'])\n",
      "(u'a network service curve approach for the stochastic analysis of networks', u'the stochastic network calculus is an evolving new methodology for backlog and delay analysis of networks that can account for statistical multiplexing gain. this paper advances the stochastic network calculus by deriving a network service curve, which expresses the service given to a flow by the network as a whole in terms of a probabilistic bound. the presented network service curve permits the calculation of statistical end-to-end delay and backlog bounds for broad classes of arrival and service distributions. the benefits of the derived service curve are illustrated for the exponentially bounded burstiness (ebb) traffic model. it is shown that end-to-end performance measures computed with a network service curve are bounded by o ( h log h ), where h is the number of nodes traversed by a flow. using currently available techniques that compute end-to-end bounds by adding single node results, the corresponding performance measures are bounded by o ( h 3 ).', [u'network service curve', u'stochastic network calculus', u'quality-of-service'])\n",
      "(u'mitigating kinematic locking in the material point method', u'the material point method exhibits kinematic locking when traditional linear shape functions are used with a rectangular grid. the locking affects both the strain and the stress fields, which can lead to inaccurate results and nonphysical behavior. this paper presents a new anti-locking approach that mitigates the accumulation of fictitious strains and stresses, significantly improving the kinematic response and the quality of all field variables. the technique relies on the huwashizu multi-field variational principle, with separate approximations for the volumetric and the deviatoric portions of the strain and stress fields. the proposed approach is validated using a series of benchmark examples from both solid and fluid mechanics, demonstrating the broad range of modeling possibilities within the mpm framework when combined with appropriate anti-locking techniques and algorithms.', [u'material point method', u'locking', u'meshfree methods', u'particle methods'])\n",
      "(u'computational dialectic and rhetorical invention', u'this paper has three dimensions, historical, theoretical and social. the historical dimension is to show how the ciceronian system of dialectical argumentation served as a precursor to computational models of argumentation schemes such as araucaria and carneades. the theoretical dimension is to show concretely how these argumentation schemes reveal the interdependency of rhetoric and logic, and so the interdependency of the normative with the empirical. it does this by identifying points of disagreement in a dialectical format through using argumentation schemes and critical questions. the social dimension is to show how the ciceronian dialectical viewpoint integrates with the use of computational tools that can be used to support the principle of reason-based deliberation and facilitate deliberative democracy.', [u'argumentation schemes', u'informal logic', u'ciceronian rhetoric', u'carneades model', u'deliberative democracy', u'fallacies', u'persuasion'])\n",
      "(u\"the roadmaker's algorithm for the discrete pulse transform\", u\"the discrete pulse transform (dpt) is a decomposition of an observed signal into a sum of pulses, i.e., signals that are constant on a connected set and zero elsewhere. originally developed for 1-d signal processing, the dpt has recently been generalized to more dimensions. applications in image processing are currently being investigated. the time required to compute the dpt as originally defined via the successive application of lulu operators (members of a class of minimax filters studied by rohwer) has been a severe drawback to its applicability. this paper introduces a fast method for obtaining such a decomposition, called the roadmaker's algorithm because it involves filling pits and razing bumps. it acts selectively only on those features actually present in the signal, flattening them in order of increasing size by sub-tracing an appropriate positive or negative pulse, which is then appended to the decomposition. the implementation described here covers 1-d signal as well as two and 3-d image processing in a single framework. this is achieved by considering the signal or image as a function defined on a graph, with the geometry specified by the edges of the graph. whenever a feature is flattened, nodes in the graph are merged, until eventually only one node remains. at that stage, a new set of edges for the same nodes as the graph, forming a tree structure, defines the obtained decomposition. the roadmaker's algorithm is shown to be equivalent to the dpt in the sense of obtaining the same decomposition. however, its simpler operators are not in general equivalent to the lulu operators in situations where those operators are not applied successively. a by-product of the roadmaker's algorithm is that it yields a proof of the so-called highlight conjecture, stated as an open problem in 2006. we pay particular attention to algorithmic details and complexity, including a demonstration that in the 1-d case, and also in the case of a complete graph, the roadmaker's algorithm has optimal complexity: it runs in time o(m), where m is the number of arcs in the graph.\", [u'clustering algorithms', u'digital filters', u'digital signal processing', u'discrete transforms', u'multidimensional signal processing', u'nonlinear filters', u'signal analysis', u'tree graphs'])\n",
      "(u'implementation relations and test generation for systems with distributed interfaces', u'some systems interact with their environment at physically distributed interfaces called ports and we separately observe sequences of inputs and outputs at each port. as a result we cannot reconstruct the global sequence that occurred and this reduces our ability to distinguish different systems in testing or in use. in this paper we explore notions of conformance for an input output transition system that has multiple ports, adapting the widely used ioco implementation relation to this situation. we consider two different scenarios. in the first scenario the agents at the different ports are entirely independent. alternatively, it may be feasible for some external agent to receive information from more than one of the agents at the ports of the system, these local behaviours potentially being brought together and here we require a stronger implementation relation. we define implementation relations for these scenarios and prove that in the case of a single-port system the new implementation relations are equivalent to ioco. in addition, we define what it means for a test case to be controllable and give an algorithm that decides whether this condition holds. we give a test generation algorithm to produce sound and complete test suites. finally, we study two implementation relations to deal with partially specified systems.', [u'formal approaches to testing', u'systems with distributed ports', u'formal methodologies to develop distributed software systems'])\n",
      "(u'dual-centers type-2 fuzzy clustering framework and its verification and validation indices', u'the clustering model considers dual-centers rather than single centers. the dual-centers type-2 clustering model and algorithm are proposed. the relations among parameters of the proposed model are explained. the degrees of belonging to the clusters are defined by type-2 fuzzy numbers. the verification and verification indices are developed for model evaluation.', [u'dual-centers clustering', u'interval type-2 fuzzy clustering', u'pcm', u'cluster center uncertainty', u'validation index', u'verification index'])\n",
      "(u'generalized sharing in survivable optical networks', u'shared path protection has been demonstrated to be a very efficient survivability scheme for optical networking. in this scheme, multiple backup paths can share a given optical channel if their corresponding primary routes are not expected to fail simultaneously. the focus in this area has been the optimization of the total channels (i.e., bandwidth) provisioned in the network through the intelligent routing of primary and backup routes. in this work, we extend the current path protection sharing scheme and introduce the generalized sharing concept. in this concept, we allow for additional sharing of important node devices. these node devices (e.g., optical-electronic-optical regenerators (oeos), pure all-optical converters, etc.) constitute the dominant cost factor in an optical backbone network and the reduction of their number is of paramount importance. for demonstration purposes, we extend the concept of 1:n shared path protection to allow for the sharing of electronic regenerators needed for coping with optical transmission impairments. both design and control plane issues are discussed through numerical examples. considerable cost reductions in electronic budget are demonstrated.', [u'optical networks', u'shared protection'])\n",
      "(u'on the usefulness of knowledge of error variances in the consistent estimation of an unreplicated ultrastructural model', u'this article considers an unreplicated ultrastructural model and discusses the asymptotic properties of three consistent estimators of slope parameter arising from the knowledge of measurement error variances. conditions are deduced when knowing the error variances associated with both the study and the explanatory variables is more/less beneficial than using a single error variance in the formulation of slope estimators.', [u'measurement errors', u'reliability ratio', u'error variance', u'ultrastructural model'])\n",
      "(u'exact solution of the heat equation with boundary condition of the fourth kind by hes variational iteration method', u'in this paper, solutions of the heat equation with the boundary condition of the fourth kind are presented. the proposed solution is based on hes variational iteration method, after the application of which the exact solution of the problem is obtained.', [u'heat equation', u'variational iteration method'])\n",
      "(u'efficient neighborhood search for the one-machine earlinesstardiness scheduling problem', u'this paper addresses the one-machine scheduling problem where the objective is to minimize a sum of costs such as earlinesstardiness costs. since the sequencing problem is np-hard, local search is very useful for finding good solutions. unlike scheduling problems with regular cost functions, the scheduling (or timing) problem is not trivial when the sequence is fixed. therefore, the local search approaches must deal with both job interchanges in the sequence and the timing of the sequenced jobs. we present a new approach that efficiently searches in a large neighborhood and always returns a solution for which the timing is optimal.', [u'scheduling', u'single machine', u'earlinesstardiness cost', u'neighborhoods', u'search method'])\n",
      "(u'power characteristics of inductive interconnect', u'the width of an interconnect line affects the total power consumed by a circuit. the effect of wire sizing on the power characteristics of an inductive interconnect line is presented in this paper. the matching condition between the driver and the load affects the power consumption since the short-circuit power dissipation may decrease and the dynamic power will increase with wider lines. a tradeoff, therefore, exists between short-circuit and dynamic power in inductive interconnects. the short-circuit power increases with wider linewidths only if the line is underdriven. the power characteristics of inductive interconnects therefore may have a great influence on wire sizing optimization techniques. an analytic solution of the transition time of a signal propagating along an inductive interconnect with an error of less than 15% is presented. the solution is useful in wire sizing synthesis techniques to decrease the overall power dissipation. the optimum linewidth that minimizes the total transient power dissipation is determined. an analytic solution for the optimum width with an error of less than 6% is presented. for a specific set of line parameters and resistivities, a reduction in power approaching 80% is achieved as compared to the minimum wire width. considering the driver size in the design process, the optimum wire and driver size that minimizes the total transient power is also determined.', [u'characteristic impedance', u'dynamic power', u'inductive interconnect', u'short-circuit power', u'transient power dissipation', u'underdamped systems'])\n",
      "(u'convergence acceleration of rungekutta schemes for solving the navierstokes equations', u'the convergence of a rungekutta (rk) scheme with multigrid is accelerated by preconditioning with a fully implicit operator. with the extended stability of the rungekutta scheme, cfl numbers as high as 1000 can be used. the implicit preconditioner addresses the stiffness in the discrete equations associated with stretched meshes. this rk/implicit scheme is used as a smoother for multigrid. fourier analysis is applied to determine damping properties. numerical dissipation operators based on the roe scheme, a matrix dissipation, and the cusp scheme are considered in evaluating the rk/implicit scheme. in addition, the effect of the number of rk stages is examined. both the numerical and computational efficiency of the scheme with the different dissipation operators are discussed. the rk/implicit scheme is used to solve the two-dimensional (2-d) and three-dimensional (3-d) compressible, reynolds-averaged navierstokes equations. turbulent flows over an airfoil and wing at subsonic and transonic conditions are computed. the effects of the cell aspect ratio on convergence are investigated for reynolds numbers between 5.7106 5.7  10 6 and 100106 100  10 6 . it is demonstrated that the implicit preconditioner can reduce the computational time of a well-tuned standard rk scheme by a factor between 4 and 10.', [u'Navier\\u2013Stokes', u'Runge\\u2013Kutta', u'Implicit preconditioning', u'Fourier analysis', u'Multigrid'])\n",
      "(u'realizations of the game domination number', u'domination game is a game on a finite graph which includes two players. first player, dominator, tries to dominate a graph in as few moves as possible; meanwhile the second player, staller, tries to hold him back and delay the end of the game as long as she can. in each move at least one additional vertex has to be dominated. the number of all moves in the game in which dominator makes the first move and both players play optimally is called the game domination number and is denoted by (gamma _g). the total number of moves in a staller-start game is denoted by (gamma _g^{prime }). it is known that (|gamma _g(g)-gamma _g^{prime }(g)|le 1) for any graph (g). graph (g) realizes a pair ((k,l)) if (gamma _g(g)=k) and (gamma _g^{prime }(g)=l). it is shown that pairs ((2k,2k-1)) for all (kge 2) can be realized by a family of 2-connected graphs. we also present 2-connected classes which realize pairs ((k,k)) and ((k,k+1)). exact game domination number for combs and 1-connected realization of the pair ((2k+1,2k)) are also given.', [u'domination game', u'game domination number', u'realizations'])\n",
      "(u'lumiproxy: a hybrid representation of image-based models', u'in this paper, we present a hybrid representation of image-based models combining the textured planes and the hierarchical points. taking a set of depth images as input, our method starts from classifying input pixels into two categories, indicating the planar and non-planar surfaces respectively. for the planar surfaces, the geometric coefficients are reconstructed to form the uniformly sampled textures. for nearly planar surfaces, some textured planes, called lumiproxies, are constructed to represent the equivalent visual appearance. the hough transform is used to find the positions of these textured planes, and optic flow measures are used to determine their textures. for remaining pixels corresponding to the non-planar geometries, the point primitive is applied, reorganized as the obb-tree structure. then, texture mapping and point splatting are employed together to render the novel views, with the hardware acceleration.', [u'lumiproxy', u'sampling', u'surface fitting', u'image-based rendering'])\n",
      "(u'constraint based methods for biological sequence analysis', u\"the need for processing biological information is rapidly growing, owing to the masses of new information in digital form being produced at this time. old methodologies for processing it can no longer keep up with this rate of growth. the methods of artificial intelligence (ai) in general and of language processing in particular can offer much towards solving this problem. however, interdisciplinary research between language processing and molecular biology is not yet widespread, partly because of the effort needed for each specialist to understand the other one's jargon. we argue that by looking at the problems of molecular biology from a language processing perspective, and using constraint based logic methodologies we can shorten the gap and make interdisciplinary collaborations more effective. we shall discuss several sequence analysis problems in terms of constraint based formalisms such concept formation rules, constraint handling rules (chr) and their grammatical counterpart, chrg. we postulate that genetic structure analysis can also benefit from these methods, for instance to reconstruct from a given rna secondary structure, a nucleotide sequence that folds into it. our proposed methodologies lend direct executability to high level descriptions of the problems at hand and thus contribute to rapid while efficient prototyping.\", [u'protein structure', u'rna secondary structure', u'gene prediction', u'concept formation', u'constraint handling rules', u'constraint handling rule grammars'])\n",
      "(u'adaptive load balancing algorithm for multiple homing mobile nodes', u'in places where mobile users can access multiple wireless networks simultaneously, a multipath scheduling algorithm can benefit the performance of wireless networks and improve the experience of mobile users. however, existing literature shows that it may not be the case, especially for tcp flows. according to early investigations, there are mainly two reasons that result in bad performance of tcp flows in wireless networks. one is the occurrence of out-of-order packets due to different delays in multiple paths. the other is the packet loss which is resulted from the limited bandwidth of wireless networks. to better exploit multipath scheduling for tcp flows, this paper presents a new scheduling algorithm named adaptive load balancing algorithm (albam) to split traffic across multiple wireless links within the isp infrastructure. targeting at solving the two adverse impacts on tcp flows, albam develops two techniques. firstly, albam takes advantage of the bursty nature of tcp flows and performs scheduling at the flowlet granularity where the packet interval is large enough to compensate for the different path delays. secondly, albam develops a packet number estimation algorithm (pnea) to predict the buffer usage in each path. with pnea, albam can prevent buffer overflow and schedule the tcp flow to a less congested path before it suffers packet loss. simulations show that albam can provide better performance to tcp connections than its other counterparts.', [u'multiple path scheduling', u'multiple interface', u'local domain'])\n",
      "(u'query by output', u'it has recently been asserted that the usability of a database is as important as its capability. understanding the database schema, the hidden relationships among attributes in the data all play an important role in this context. subscribing to this viewpoint, in this paper, we present a novel data-driven approach, called query by output (qbo) , which can enhance the usability of database systems. the central goal of qbo is as follows: given the output of some query q on a database d , denoted by q ( d ), we wish to construct an alternative query q ? such that q ( d ) and q ? ( d ) are instance-equivalent. to generate instance-equivalent queries from q ( d ), we devise a novel data classification-based technique that can handle the at-least-one semantics that is inherent in the query derivation. in addition to the basic framework, we design several optimization techniques to reduce processing overhead and introduce a set of criteria to rank order output queries by various notions of utility. our framework is evaluated comprehensively on three real data sets and the results show that the instance-equivalent queries we obtain are interesting and that the approach is scalable and robust to queries of different selectivities.', [u'query by output', u'at-least-one semantics', u'instance-equivalent queries'])\n",
      "(u'three-dimensional quantitative structureactivity relationships study on hiv-1 reverse transcriptase inhibitors in the class of dipyridodiazepinone derivatives, using comparative molecular field analysis1', u'a three-dimensional quantitative structureactivity relationships (3d qsar) method, comparative molecular field analysis (comfa), was applied to a set of dipyridodiazepinone (nevirapine) derivatives active against wild-type (wt) and mutant-type (y181c) hiv-1 reverse transcriptase. the starting geometry of dipyridodiazepinone was taken from x-ray crystallographic data. all 75 derivatives, divided into a training set of 53 compounds and a test set of 22 molecules, were then constructed and full geometrical optimizations were performed, based on a semiempirical molecular orbital method (am1). comfa was used to discriminate between structural requirements for wt and y181c inhibitory activities. the resulting comfa models yield satisfactory predictive ability regarding wt and y181c inhibitions, with r2cv = 0.624 and 0.726, respectively. comfa contour maps reveal that steric and electrostatic interactions corresponding to the wt inhibition amount to 58.5% and 41.5%, respectively, while steric and electrostatic effects have approximately equal contributions for the explanation of inhibitory activities against y181c. the contour maps highlight different characteristics for different types of wild-type and mutant-type hiv-1 rt. in addition, these contour maps agree with experimental data for the binding topology. consequently, the results obtained provide information for a better understanding of the inhibitorreceptor interactions of dipyridodiazepinone analogs.  2000 elsevier science inc.', [u'hiv-1 rt', u'nevirapine', u'nnrti', u'comfa', u'3d-qsar', u'quantum chemical calculations', u'molecular modeling'])\n",
      "(u'a shared-memory implementation of the hierarchical radiosity method', u'the radiosity method is a simulation method from computer graphics to visualize the global illumination in scenes containing diffuse objects within an enclosure. a variety of realizations (including parallel approaches) were proposed to achieve a high efficiency while guaranteeing the same accuracy of the graphical representation. the hierarchical radiosity method reduces the computational costs considerably but results in a highly irregular algorithm which makes a parallel implementation more difficult. we investigate a task-oriented shared memory implementation and present optimizations with different behavior concerning locality and granularity. to be able to concentrate on load balancing and scalability issues, we use a shared-memory machine with uniform memory access time, the sb-pram